{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3682a666-2349-4757-bb47-1834fe6b069f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# HW1-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396d1509-d98c-4d09-9273-855ffe056e3f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Problem 2\n",
    "\n",
    "Prove that\n",
    "$$\n",
    "    \\sum_{j=0}^{k} \\begin{pmatrix}n\\\\j\\end{pmatrix} \\begin{pmatrix}m\\\\k-j\\end{pmatrix} = \\begin{pmatrix}m+n\\\\k\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4b458b-a23d-42d5-967b-ff8908abc937",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Problem 3\n",
    "\n",
    "A fair die is rolled $n$ times. What is the probability that at least 1 of the 6 values never appears? Give a formula answer with derivation. Hint: use inclusion-exclusion formula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5994953-30f2-4e44-b47d-332461d9f1d0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Solution 3\n",
    "\n",
    "Let $A_i$ be the event that $i$-th value does not appear. Then, $\\bigcup\\limits_{i=1}^6 A_i$ is the event that at least one values does not appear. Let $B_{ij}$ be the event that $i$-th value does not appear on $j$-th roll. Then,\n",
    "$$\n",
    "P(A_i) = \\prod\\limits_{j=1}^n P(B_{ij}) = \\left(P(B_{i1})\\right)^n = \\left( \\frac56 \\right)^n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37b369b-c2d9-4bf2-ae73-f40393b0b0c9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Now, in order to use the inclusion-exclusion formula, we will need the probabilities of intersections. To get those, consider the probability of the event $A_i \\cap A_j$, i.e. that values $i$ and $j$ did not appear:\n",
    "$$\n",
    "P(A_i \\cap A_j) = \\left( \\frac46 \\right)^n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e19ec22-31a7-43c0-bf66-8d09622476d6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Finally, consider the fact that the values are free to be any of the six, so we need to choose them. Then,\n",
    "$$\n",
    "P\\left(\\bigcup\\limits_{i=1}^n A_i\\right) = \\begin{pmatrix} 6\\\\1 \\end{pmatrix} \\left( \\frac56 \\right)^n - \\begin{pmatrix} 6\\\\2 \\end{pmatrix} \\left( \\frac46 \\right)^n + \\begin{pmatrix} 6\\\\3 \\end{pmatrix} \\left( \\frac36 \\right)^6 - \\begin{pmatrix} 6\\\\4 \\end{pmatrix} \\left( \\frac26 \\right)^n + \\begin{pmatrix} 6\\\\5 \\end{pmatrix} \\left( \\frac16 \\right)^n - \\begin{pmatrix} 6\\\\6 \\end{pmatrix} \\left( \\frac06 \\right)^n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f9211c-c7c9-4d55-a2d5-fa0805dd0e0b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Problem 4\n",
    "\n",
    "There are two baskets. The first basket contains one white ball, the second basket contains one black ball. One basket is chosen randomly and a white ball is put into the chosen basket. The balls in this basket are shuffled. Then one ball is extracted from this basket. This ball turns out to be white. What is the posterior probability that the second ball drawn from this basket is also white?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385e4a23-7c2a-45dc-8bb5-251565d09cbd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Solution 4\n",
    "\n",
    "Probability that the second ball drawn from this basket is also white is the same as probability that the basket containing a white ball was chosen initially. Denote the event that the basket with white ball was chosen as $B$, and the event that he first drawn ball was white as $A$, then using the Bayes rule\n",
    "$$\n",
    "\\mathbb{P}(B|A) = \\frac{\\mathbb{P}(A|B)\\mathbb{P}(B)}{\\mathbb{P}(A|B)\\mathbb{P}(B) + \\mathbb{P}(A|\\overline{B})\\mathbb{P}(\\overline{B})} = \\frac{1 \\cdot \\frac12}{1 \\cdot \\frac12 + \\frac12 \\cdot \\frac12} = \\frac23\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61717a5e-f1fd-4ed4-b064-85d38009366d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Problem 5\n",
    "\n",
    "If you get a positive result on a COVID test that only gives a false positive with probability 0.001 (true positive with probability 0.999), what’s the chance that you've actually got COVID, if \n",
    "- (1 point) The prior probability that a person has COVID is 0.01\n",
    "- (1 point) The prior probability that a person has COVID is 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a7f9f1-af68-45ad-a85e-51aaa3ce6519",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Problem 8\n",
    "\n",
    "(2 bonus points) The cloakroom of a theater has randomly permuted all $n$ visitors' hats. Find the probability that at least one visitor gets his hat. Give a formula answer with derivation. Given $n=4$, give a number answer. Hint: use inclusion-exclusion formula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f007325-46e8-45c2-aec2-c70d0e11b478",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Solution 8\n",
    "\n",
    "Denote $A_i$ the event that visitor $i$ gets his hat. Probability of this event is easily obtained: if we fix this visitor as the first, he has the choice of all the hats\n",
    "$$\n",
    "\\mathbb{P}(A_i) = \\frac1n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6832230e-f036-4845-ab88-9f3266ed371b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Probability of intersection of two of these events is also easy, the second visitor has the choice of all but one hat (picked by first visitor)\n",
    "$$\n",
    "\\mathbb{P}(A_i) = \\frac1n \\frac{1}{n-1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bbe3a5-92f0-46c5-bb37-4722bd0f2565",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Intersections of more events follow similar argumentation. Then, using these events we write\n",
    "$$\n",
    "\\mathbb{P}(\\text{at least one visitor get their hats}) = \\mathbb{P}(\\bigcup_{i=1}^n A_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412912e5-67f6-4b11-9323-d339dbb7cbcf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Using inclusion-exclusion formula:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathbb{P}(\\bigcup_{i=1}^n A_i) & = \\sum_{i=1}^n \\mathbb{P}(A_i) - \\sum_{1 \\leqslant i < j \\leqslant n} \\mathbb{P}(A_i \\cap A_j) + \\ldots + (-1)^{n+1} \\mathbb{P}(A_1 \\cap \\ldots \\cap A_n) = \\\\\n",
    "    & = \\sum_{i=1}^n \\frac1n - \\sum_{1 \\leqslant i < j \\leqslant n} \\frac1n \\frac{1}{n-1} + \\ldots + (-1)^{n+1} \\frac{1}{n!} = \\\\\n",
    "    & = n \\cdot \\frac1n - \\frac{n (n-1)}{2!} \\frac1n \\frac{1}{n-1} + \\ldots + (-1)^{n+1} \\frac{1}{n!} = \\\\\n",
    "    & = 1 - \\frac{1}{2!} + \\ldots + (-1)^{n+1} \\frac{1}{n!}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acec94b-2038-46d2-8fe5-38c5dfdecc85",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Problem 9\n",
    "\n",
    "(2 bonus points) You are the contestant on the Monty Hall show. Monty is trying out a new version of his game, with rules as follows. You get to choose one of three doors. One door has a car behind it, another has a computer, and the other door has a goat (with all permutations equally likely). Monty, who knows which prize is behind each door, will open a door (but not the one you chose) and then let you choose whether to switch from your current choice to the other unopened door.\n",
    "\n",
    "Suppose that Monty always opens the door that reveals your less preferred prize out of the two alternatives, e.g., if he is faced with the choice between revealing the goat or the computer, he will reveal the goat. Monty opens a door, revealing a goat. Given this information, should you switch? If you do switch, what is your probability of success in getting the car?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a821c5c-3826-4b42-8f84-0c8b28358167",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Solution 9\n",
    "\n",
    "Denote\n",
    "- Door of original choice as door 1, door that Monty opens as door 2, door that is left as door 3\n",
    "- $C_i$ the event that car is behind door $i$\n",
    "- $M_i$ the event that Monty opens door $i$\n",
    "- $G_i$ the event that goat is bedind door $i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2f97ef-e597-42a7-b8a8-e7373c80e8fd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Using Bayes rule:\n",
    "$$\n",
    "\\mathbb{P}(C_1|M_2, G_2) = \\frac{\\mathbb{P}(M_2, G_2|C_1) \\mathbb{P}(C_1)}{(\\mathbb{P}(M_2, G_2|C_1) \\mathbb{P}(C_1) + \\mathbb{P}(M_2, G_2|C_2) \\mathbb{P}(C_2) + \\mathbb{P}(M_2, G_2|C_3) \\mathbb{P}(C_3))}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(M_2, G_2 | C_1) = \\mathbb{P}(M_2 | G_2, C_1) \\mathbb{P}(G_2 | C_1) = 1 * 1/2\n",
    "$$\n",
    "$$\n",
    "\\mathbb{P}(M_2, G_2 | C_2) = \\mathbb{P}(M_2 | G_2, C_2) \\mathbb{P}(G_2 | C_2) = 0\n",
    "$$\n",
    "$$\n",
    "\\mathbb{P}(M_2, G_2 | C_3) = \\mathbb{P}(M_2 | G_2, C_3) \\mathbb{P}(G_2 | C_3) = 1 * 1/2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(C_1|M_2, G_2) = 1/2 * 1/3 / (2 * 1/2 * 1/3) = 1/2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac48ee4d-5663-4b02-873e-b143c7e3b26b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# HW4-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40fb23f-d2a2-4a9c-9ad1-3ad11cb807d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Problem 4\n",
    "\n",
    "(2 points) Consider two independent random variables $X \\sim F_X$ and $Y \\sim F_Y$. Find the CDF of random variables $Z_1 = \\max\\left(X, Y\\right)$ (it means that for every outcome $w$ we have $Z_1(w) = \\max\\left(X(w), Y(w)\\right)$, so $Z_1$ jumps between values of $X$ and $Y$) and $Z_2 = \\min\\left(X, Y\\right)$ (same reasoning applies)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5192e29-ffe5-491c-87d0-018c1791e0cc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Solution 4\n",
    "\n",
    "1. $Z_1 = \\max\\left(X, Y\\right)$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    F_{Z_1}(z) & = \\mathbb{P}(Z_1 \\leqslant z) = \\mathbb{P}(\\max\\left(X, Y\\right) \\leqslant z) = \\\\\n",
    "    & = \\mathbb{P}(X \\leqslant z \\text{ and } Y \\leqslant z) = \\mathbb{P}(X \\leqslant z) \\mathbb{P}(Y \\leqslant z) = F_X(z) F_Y(z)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a579cf58-3f26-4618-b954-4ab3eed62a8f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "2. $Z_2 = \\min\\left(X, Y\\right)$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    F_{Z_2}(z) & = \\mathbb{P}(Z_2 \\leqslant z) = \\mathbb{P}(\\min\\left(X, Y\\right) \\leqslant z) = \\\\\n",
    "    & = \\mathbb{P}(X \\leqslant z \\text{ or } Y \\leqslant z) = \\mathbb{P}(X \\leqslant z) + \\mathbb{P}(Y \\leqslant z) - \\mathbb{P}(X \\leqslant z \\text{ and } Y \\leqslant z) = \\\\\n",
    "    & = F_X(z) + F_Y(z) - F_X(z) F_Y(z)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6b637e-f8f2-4fef-a83d-67ba98f5c817",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Problem 6\n",
    "\n",
    "(2 bonus points) A good student solves a problem correctly with probability 0.95, while a bad student — with probability 0.15. What is the minimal number of problems that the test should include so that the probability that good student does not pass the test does not exceed 0.01, and the probability that the bad student passes the test does not exceed 0.1? Passing the test means solving strictly more than half of the problems. You can use Python to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49330a1c-19e9-45be-bdb3-db851ad4c925",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Solution 6\n",
    "\n",
    "Let's have $Bi(n, 0.95)$ describing how many problems a good student solves and $Bi(n, 0.15)$ describing how many problems a bad student solves. We then need $n$ such that:\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\operatorname{CDF}_{Bi(n, 0.95)}(\\lfloor \\frac{n}{2} \\rfloor) \\leqslant 0.01, \\\\\n",
    "\\operatorname{SF}_{Bi(n, 0.15)}(\\lceil \\frac{n}{2} \\rceil) \\leqslant 0.1.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01710fce-beea-415d-9994-2fa5304b16a0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Problem 7\n",
    "\n",
    "(3 bonus points) Two players are playing a game. The first player says a number $p_1$ between 0 and 1. The second player, knowing the number of the first player, says a number $p_2$ between 0 and 1. Then, with probability $p_1$ the first number becomes zero, and with probability $p_2$ the second number becomes zero. The player whose number is greater, wins.\n",
    "- (2 bonus points) What is the optimal winning strategy of player two?\n",
    "- (1 bonus point) What is the optimal winning strategy of player one, if player two follows strategy from the previous point?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffc2ca9-48cd-41b4-9b63-1262d8e82ff6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "1. Denote $n_i$ the numbers announced by player $i$. Let's consider four cases.\n",
    "\n",
    "    Consider that the first player has announced a number close to 1. If the second player announces a number \\textbf{smaller} than the first player, he wins only when the number of the first player is nullified: $\\mathbb{P}(\\text{player 2 wins} | n_2 < n_1 ) = n_1 \\cdot (1 - n_2)$. If, however, the second player announces a number \\textbf{larger} than the first player, he wins in both cases (if his number is not nullified): $\\mathbb{P}(\\text{player 2 wins} | n_2 > n_1 ) = n_1 \\cdot (1 - n_2) + (1 - n_1) \\cdot (1 - n_2) = (1 - n_2)$, which is \\textbf{higher}, but gets smaller with $n_2$. So, for large $n_1$, the best $n_2$ is just above $n_1$ or $n_2 = n_1 + \\varepsilon$.\n",
    "   \n",
    "   If the $n_1$ is small, then the inequality changes sign, so the best $n_2$ is just above zero or $n_2 = \\varepsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3fc5e2-e9e9-4f48-b7c4-0c08f2d9e130",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "<img src=\"3d_plot.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e002d6b2-ead6-4eda-9960-a9f609830995",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "2. By looking at the image above, it is obvious that the smallest probability of winning is when $n_1 = 0.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cdc6cf-5a74-4c53-bf8f-599790a24ccc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# HW6-7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7270a0c6-2eda-47cc-a8f0-c9c3a0ec4052",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Problem 1\n",
    "\n",
    "(1 points) You have $n$ enumerated letters and $n$ enumerated envelopes. You randomly put letters into envelopes. What is the expected value of the number of coinciding numbers of the letter and its envelope?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6b133b-7c62-42ce-8392-721a95a0a4bc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Solution 1\n",
    "\n",
    "Denote $A_i$ the event that one letter coincides with envelope. The probability of this event is\n",
    "$$\n",
    "\\mathbb{P}(A_i) = \\frac1n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b9e549-7c39-4430-8b21-62f799103cf2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Denote $X_i$ the indicator r.v. of event $A_i$. Denote $N$ the number of coincidences, then\n",
    "$$\n",
    "\\mathbb{E}[N] = \\mathbb{E}[\\sum_{i=1}^n X_i] = \\sum_{i=1}^n \\mathbb{E}[X_i] = n \\frac1n = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542254ec-d941-42f0-9e53-211faac92d95",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Problem 5\n",
    "\n",
    "(2 points) Consider independent random variables $X \\sim Exp(\\lambda_X)$ and $Y \\sim Exp(\\lambda_Y)$.\n",
    "\n",
    "1. Find the CDF of $Z = \\min\\{X, Y\\}$.\n",
    "\n",
    "2. Let $\\lambda_X = \\lambda_Y$. Find the CDF of $Z = X + Y$. This will be a (very simple case of) \\textbf{Gamma distribution}. Hint: use the convolution formula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1441c468-ea41-4ec9-a81a-debcad97534d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Solution 5\n",
    "\n",
    "1. Based on HW4-5 Problem 4:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "F_Z(z) & = F_X(z) + F_Y(z) - F_X(z) F_Y(z) = \\\\\n",
    "& = 1 - e^{-\\lambda_X z} + 1 - e^{-\\lambda_Y z} - (1 - e^{-\\lambda_X z}) (1 - e^{-\\lambda_Y z}) = \\\\\n",
    "& = 1 - e^{- (\\lambda_X + \\lambda_Y) z}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de38756a-dc12-442a-8625-32a81c3c6a98",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "2. Let $\\lambda_X = \\lambda_Y = \\lambda$. Convolution formula for PDF:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f_Z(z) & = \\int_{-\\infty}^\\infty \\lambda e^{- \\lambda t} \\lambda e^{- \\lambda (z - t)} dt = \\\\\n",
    "& = \\lambda^2 e^{- \\lambda z} \\int_0^z dt = \\lambda^2 z e^{- \\lambda z}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcd9a5e-addb-4660-83c9-2cc051814861",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "CDF:\n",
    "$$\n",
    "F_Z(z) = \\int_0^z \\lambda^2 x e^{- \\lambda x} dx = \\lambda^2 \\frac{1 - e^{-\\lambda z} (\\lambda z + 1)}{\\lambda^2} = 1 - e^{-\\lambda z} (\\lambda z + 1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4284e5-ccf5-46d5-aaba-e41208a59722",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Problem 6\n",
    "\n",
    "(4 bonus points) Compute expectation (2 bonus points) and variance (2 bonus points) of Geometric distribution. Hints:\n",
    "1. Obtain the series for expectation in terms of $p$ and $q$.\n",
    "2. Compare the series with geometric series in $q$, for which we know that it converges, and we know the limit.\n",
    "3. Differentiate the geometric series. Because the geometric series converges, we can interchange sum and differential operators. Compare the series for expectation with differentiated geometric series.\n",
    "4. Make the necessary changes and obtain the expectation.\n",
    "5. Use LOTUS to get series for $\\mathbb{E}[X^2]$.\n",
    "6. Compare with differentiated geometric series. Make adjustments, differentiate again.\n",
    "7. Obtain the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45197a4d-0c73-4e73-8896-eb95fe68cc89",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Solution 6\n",
    "\n",
    "1. Series for expectation:\n",
    "$$\n",
    "\\mathbb{E}[X] = \\sum_{k=0}^\\infty k p q^k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8673e1-326d-43f7-b42d-82aaa45b4d6d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "2. Geometric series (since $0 < q < 1$):\n",
    "$$\n",
    "\\sum_{k=0}^\\infty q^k = \\frac{1}{1-q}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0454aa-ba2b-4d1c-854c-1d7bed31d126",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "3. Differentiate w.r.t. $q$ (we can do that because the series converges):\n",
    "$$\n",
    "\\sum_{k=0}^\\infty k q^{k-1} = \\frac{1}{(1-q)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df9201-cb09-4215-bfaf-d7f8ab4b3bdd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "4. Multiply by $pq$:\n",
    "$$\n",
    "\\mathbb{E}[X] = \\sum_{k=0}^\\infty k p q^k = \\frac{pq}{p^2} = \\frac{q}{p}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e17a5e-aa98-4be6-a5ed-9250a9dd764c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "5. Using LOTUS:\n",
    "$$\n",
    "\\mathbb{E}[X^2] = \\sum_{k=0}^\\infty k^2 \\mathbb{P}(X = k) = \\sum_{k=0}^\\infty k^2 p q^k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5206dc7-6d35-4183-a699-474334f16001",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "6. Differentiated geometric series:\n",
    "$$\n",
    "\\sum_{k=0}^\\infty k q^{k-1} = \\frac{1}{(1-q)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb3589-e9cb-44a8-aa65-fc6c4621c6b8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Multiply by $q$:\n",
    "$$\n",
    "\\sum_{k=1}^\\infty k q^k = \\frac{q}{(1-q)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba786bd-6834-4ddb-b3b2-dfc96ab5af44",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Differentiate again:\n",
    "$$\n",
    "\\sum_{k=1}^\\infty k^2 q^{k-1} = \\frac{1+q}{(1-q)^3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3beee9b-be49-444f-bff0-8e8e97a4574b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Multiply by $pq$:\n",
    "$$\n",
    "\\mathbb{E}[X^2] = \\sum_{k=1}^\\infty k^2 p q^k = pq \\frac{1+q}{(1-q)^3}  = \\frac{q(1+q)}{p^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cec2b1-ca7f-4ec8-bfb5-14d7d6147984",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "7. Obtain variance:\n",
    "$$\n",
    "\\mathbb{V}\\text{ar}(X) = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2 = \\frac{q(1+q)}{p^2} - \\frac{q^2}{p^2} = \\frac{q}{p^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee1c0e1-be39-420e-a70e-23b2d729ca52",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Problem 7\n",
    "\n",
    "(1 bonus point) Compute expectation and variance of Negative binomial distribution. Hint: there is a relation between Negative binomial and Geometric distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954e487e-7cab-48ff-9f4f-f9efba42aa26",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Solution 7\n",
    "\n",
    "The relation is\n",
    "$$\n",
    "NBi(r, p) = \\sum_{k=1}^r Geom(p)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6faac85-acee-4412-a3f6-8bb3c75bf0ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Denote $X \\sim NBi(r, p)$ and $X_k \\sim Geom(p), k = 1, \\ldots, r$. Then,\n",
    "$$\n",
    "\\mathbb{E}[X] = \\mathbb{E}[\\sum_{k=1}^r X_k] = \\sum_{k=1}^r \\mathbb{E}[X_k] = \\frac{rq}{p}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49a4377-32cf-4aa3-b063-80cfb85c4112",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Also because $X_k$ are independent, they are uncorrelated and the variance is also linear\n",
    "$$\n",
    "\\mathbb{V}\\text{ar}(X) = \\mathbb{V}\\text{ar}(\\sum_{k=1}^r X_k) = \\sum_{k=1}^r \\mathbb{V}\\text{ar}(X_k)s = \\frac{rq}{p^2}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
