{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f7b639",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Seminar 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb7a2e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap of axiomatic definition of probability\n",
    "\n",
    "A probability space is the following tuple: $(\\Omega, \\cal{F}, \\mathbb{P})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-petroleum",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Sample space** $\\Omega$\n",
    "- **Set of events** $\\cal{F}$\n",
    "- **Probability measure** $\\mathbb{P}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-madison",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Set of events is $\\cal{F} \\subset 2^\\Omega$ ($\\sigma$-algebra), such that\n",
    "1. $\\Omega \\in \\cal{F}$\n",
    "2. If $A \\in \\cal{F}$, then $\\overline{A} \\in \\cal{F}$ (closed under complement operation)\n",
    "3. If $A_1, A_2, \\ldots \\in \\cal{F}$, then $\\bigcup_{k=1}^\\infty A_k \\in \\cal{F}$ (closed under countable union operation)\n",
    "\n",
    "The pair $(\\Omega, \\cal{F})$ is called a measurable space. Set $A$ is called measurable if $A \\in \\mathcal{F}$.\n",
    "\n",
    "Probability measure is $\\mathbb{P}: \\cal{F} \\to \\mathbb{R}_+$, such that\n",
    "1. $\\mathbb{P}(\\Omega) = 1$\n",
    "2. If $A_1, A_2, \\ldots \\in \\cal{F}$ and $A_i \\cap A_j = \\varnothing$ for $i\\neq j$, then $\\mathbb{P}\\left(\\bigcup_{k=0}^\\infty A_k \\right) = \\sum_{k=1}^\\infty \\mathbb{P}(A_k)$ ($\\sigma$-additivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-february",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 1\n",
    "\n",
    "Let\n",
    "- $\\Omega = (0, 1]$\n",
    "- $\\mathcal{F} = 2^{(0, 1]}$\n",
    "- $\\mathbb{P}(A) = \\tfrac{k}{n}$, where $k$ is the number of points like $\\tfrac{i}{n}, i \\in \\{1, \\ldots, n\\}$ in $A$\n",
    "\n",
    "We can check that all the necessary conditions are satisfied:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-musical",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. $\\Omega = (0, 1] \\subset 2^{(0, 1]} = \\mathcal{F}$\n",
    "2. If $A \\subset (0, 1] \\in \\mathcal{F}$, then $\\overline{A} \\subset (0, 1] \\in \\mathcal{F}$ as well\n",
    "3. If $A_1, A_2, \\ldots \\subset (0, 1] \\in \\mathcal{F}$, then all their elements are in $(0, 1]$, and thus the union $\\bigcup_{k=1}^\\infty A_k \\subset (0, 1] \\in \\mathcal{F}$\n",
    "4. $\\mathbb{P}(\\Omega) = \\mathbb{P}((0,1]) = \\tfrac{n}{n} = 1$\n",
    "5. If $A_1$ and $A_2 \\in \\cal{F}$ and $A_1 \\cap A_2 = \\varnothing$, then $\\tfrac{k_1 + k_2}{n} = \\mathbb{P}\\left(A_1 \\cup A_2 \\right) = \\mathbb{P}(A_1) + \\mathbb{P}(A_2) = \\tfrac{k_1}{n} + \\tfrac{k_2}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-mercury",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 2\n",
    "\n",
    "Let\n",
    "- $\\Omega = (0, 1]$\n",
    "- $\\mathcal{F}$ is the set of all half-intervals $(a, b]$ in $(0, 1]$\n",
    "- $\\mathbb{P}((a, b]) = b - a$ (length of half-interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-height",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this case, $\\mathcal{F}$ is not a $\\sigma$-algebra, because union of half-intervals is not necessarily a half-interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-dynamics",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We need to add something else to $\\mathcal{F}$. We can add all finite unions of half-intervals, then $\\mathcal{F}$ will be an algebra, but still not $\\sigma$-algebra. We can **not** build such $\\mathcal{F}$ by hand, but it exists according to the following theorem.\n",
    "\n",
    "**Theorem 1:** Let $\\mathcal{A}$ be some set of subsets of set $A$, then exists a minimal $\\sigma$-algebra $\\sigma(\\mathcal{A})$, which contains $\\mathcal{A}$. It means that this $\\sigma(\\mathcal{A})$ will be a part of any larger $\\sigma$-algebra, that contains $\\mathcal{A}$.\n",
    "\n",
    "**Theorem 2 (Caratheodory Theorem):** Let probability measure $\\mathbb{P}$ be defined on algebra $\\mathcal{A}$ and $\\sigma$-additive on it. Then $\\mathbb{P}$ can be extended to $\\sigma(\\mathcal{A})$ uniquely.\n",
    "\n",
    "This gives us the following result: The measure $\\mathbb{P}$, defined on half-intervals in $(0, 1]$ as $\\mathbb{P}((a, b]) = b - a$, can be uniquely extended to a minimal $\\sigma$-algebra containing such half-intervals. Then it will be a probability measure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-culture",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lebesgue measure\n",
    "\n",
    "What we just defined is called **probabilistic Lebesgue measure** $\\lambda((a, b]) = \\mathbb{P}((a, b]) = b - a$. Next, we can define non-probabilistic measure.\n",
    "\n",
    "A mapping $\\mu: \\mathcal{F} \\to [0, +\\infty)$ is called a **measure** if it is additive and $\\sigma$-additive (we simply ignore the $\\mathbb{P}(\\Omega) = 1$ property).\n",
    "\n",
    "So we defined $\\lambda$ on $(0, 1]$. We can naturally extend it to $(n, n+1]$: the measure of set $A \\subset 2^{(n, n+1]}$ will be equal to measure of set $B \\subset 2^{(0, 1]}$ obtained by shifting the set.\n",
    "\n",
    "Finally, for a general set $A \\subset \\mathbb{R}$, define\n",
    "$$\n",
    "\\lambda(A) = \\sum\\limits_{n \\in \\mathbb{Z}} \\lambda\\left( A \\cap (n, n+1] \\right)\n",
    "$$\n",
    "\n",
    "This is the **Lebesgue measure on real line**, what we usually call length."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-reconstruction",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Borel $\\sigma$-algebra\n",
    "\n",
    "Minimal $\\sigma$-algebra $\\mathcal{B}(A)$ that contains all open subsets of $A$ is called **Borel $\\sigma$-algebra**.\n",
    "\n",
    "**Lemma:** Borel $\\sigma$-algebra of subsets of $(0, 1]$ coincides with minimal $\\sigma$-algebra, containing all half-intervals.\n",
    "\n",
    "Since we extended Lebesgue measure to the whole real line, we can find measure of every set in $\\mathcal{B}(\\mathbb{R})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-database",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Measurable mapping\n",
    "\n",
    "Consider\n",
    "- Two measurable spaces $(X, \\mathcal{F}_X)$ and $(Y, \\mathcal{F}_Y)$\n",
    "- A mapping $T: X \\to Y$\n",
    "- A measurable set $A \\in \\mathcal{F}_X$\n",
    "\n",
    "**Full pre-image** of $A$ under T is then\n",
    "$$\n",
    "T^{-1}(A) = \\{ x \\in X | T(x) \\in A \\}\n",
    "$$\n",
    "\n",
    "Full pre-image of $A$ under $T$ can also be measurable: $T^{-1}(A) \\in \\mathcal{F}_X$, but not necessarily. If for any measurable set $A$ its full pre-image under $T$ is measurable, we say that $T$ is a **measurable mapping**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-example",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random variables\n",
    "\n",
    "Consider probabiliy space $(\\Omega, \\mathcal{F}, \\mathbb{P})$. A **random variable** is a measurable function $X: \\Omega \\to \\mathbb{R}$ from $(\\Omega, \\mathcal{F})$ to $(\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))$.\n",
    "\n",
    "It means that the pre-image of any set $A$ in $\\mathcal{B}(\\mathbb{R})$ belongs to $\\mathcal{F}$:\n",
    "$$\n",
    "\\forall A \\in \\mathcal{B}(\\mathbb{R}) \\Longrightarrow X^{-1}(A) \\in \\mathcal{F}\n",
    "$$\n",
    "\n",
    "Think of event $B \\in \\mathcal{B}(\\mathbb{R})$ and its pre-image $A \\in \\mathcal{F}$. Naturally, the probability that random variable $X$ lies in set $B$ is the same as probability of event $A$:\n",
    "$$\n",
    "\\mathbb{P}(X \\in B) = \\mathbb{P}(X^{-1}(B)) = \\mathbb{P}(A)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-bridal",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 3\n",
    "\n",
    "Let\n",
    "- $\\Omega = [0, 1]$\n",
    "- $\\mathcal{F} = \\mathcal{B}([0, 1])$\n",
    "- $X_1(\\omega) = \\omega$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-concert",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In order to check if $X_1$ will be a random variable, we need to verify that $X_1$ is a measurable function from $([0, 1], \\mathcal{B}([0, 1]))$ to $(\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-throat",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It will be such measurable function, because the pre-image of any set $[a, b] \\in \\mathcal{B}(\\mathbb{R})$ lies in $\\mathcal{B}([0, 1])$:\n",
    "$$\n",
    "X_1^{-1}([a, b]) = [a, b] \\cap [0, 1]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-motion",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 4\n",
    "\n",
    "Let\n",
    "- $\\Omega = [0, 1]$\n",
    "- $\\mathcal{F} = \\{\\Omega, \\varnothing\\}$\n",
    "- $X_1(\\omega) = \\omega$\n",
    "\n",
    "In order to check if $X_1$ will be a random variable, we need to verify that $X_1$ is a measurable function from $([0, 1], \\mathcal{F})$ to $(\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-camcorder",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It will **not** be such measurable function, because the pre-image of e.g. $[0, 1/2] \\in \\mathcal{B}(\\mathbb{R})$ does not lie in $\\mathcal{F}$:\n",
    "$$\n",
    "X_1^{-1}([0, 1/2]) = [0, 1/2] \\not\\in \\{[0, 1], \\varnothing\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-vehicle",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Independence of random variables\n",
    "\n",
    "A **minimal $\\sigma$-algebra generated by random variable $X$** is the minimal $\\sigma$-algebra containing pre-images of all borel sets:\n",
    "$$\n",
    "\\sigma(X) = \\sigma\\{X^{-1}(B), B \\in \\mathcal{B}(\\mathbb{R})\\} = \\{X^{-1}(B), B \\in \\mathcal{B}(\\mathbb{R})\\}\n",
    "$$\n",
    "\n",
    "Random variables $X$ and $Y$ are called independent if their minimal generated $\\sigma$-algebras are independent. This means that any events $A \\in \\sigma(X)$ and $B \\in \\sigma(Y)$ should be independent:\n",
    "$$\n",
    "\\mathbb{P}(A \\cap B) = \\mathbb{P}(A) \\mathbb{P}(B)\n",
    "$$\n",
    "\n",
    "Let's say $A$ is pre-image of some borel event $B_1$ and $B$ is the pre-image of a different borel event $B_2$. Then, $\\mathbb{P}(A) = \\mathbb{P}(X^{-1}(B_1)) = \\mathbb{P}(X \\in B_1)$ and similarly for $B_2$, so finally,\n",
    "$$\n",
    "\\mathbb{P}(X \\in B_1, X \\in B_2) = \\mathbb{P}(X \\in B_1) \\mathbb{P}(X \\in B_2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-newton",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distribution of a random variable\n",
    "\n",
    "Consider probability sapce $(\\Omega, \\mathcal{F}, \\mathbb{P})$ and random variable $X: \\Omega \\to \\mathbb{R}$. We will call the image $\\mu$ of measure $\\mathbb{P}$ through the mapping $X$ **the distribution** (or distribution law) of $X$:\n",
    "$$\n",
    "\\mu(A) = \\mathbb{P}(X^{-1}(A))\n",
    "$$\n",
    "\n",
    "We will write $X \\sim \\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-hospital",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Three types of distributions\n",
    "\n",
    "**Lebesgue theorem:** Let $\\nu$ be Lenesgue measure on $\\mathbb{R}$ and $\\mu$ be any probabilistic measure, then $\\mu = \\mu_d + \\mu_s + \\mu_{ac}$, where\n",
    "- $\\mu_d$ is **discrete measure**, i.e. it is concentrated on a countable set of points.\n",
    "- $\\mu_s$ is **singular measure**, i.e. exists measurable set $S$ such that $\\nu(S) = 0$ and $\\mu_s(\\overline{S}) = 0$ and $\\forall x \\in \\mathbb{R} \\mu_s(\\{x\\}) = 0$.\n",
    "- $\\mu_{ac}$ is **absolutely continuous measure**, i.e. from $\\nu(A) = 0$ follows $\\mu_{ac}(A) = 0$ for any measurable set $A$.\n",
    "    By **Radon-Nikodim theorem**, it is equivalent to the existence of a non-negative measurable function $f: \\mathbb{R} \\to \\mathbb{R}$ called **probability density function**, such that $\\mu_{ac}(A) = \\int_A f(x) dx$.\n",
    "    \n",
    "Because the distributions are defined through the measure, any probability distribution may be viewed as a mixture of three base types: discrete, singular and continuous.\n",
    "\n",
    "Normally though, the distributions fall into just one category. Also, you never encounter singular distributions in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-hamilton",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 5\n",
    "\n",
    "Consider event $A \\in \\mathcal{F}$ and a random variable $X = \\mathbb{I}\\text{nd}_A$, an indicator:\n",
    "$$\n",
    "\\mathbb{I}\\text{nd}_A(x) = \\begin{cases}\n",
    "1, x \\in A, \\\\\n",
    "0, \\text{else}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(X = 1) = \\mathbb{P}(A) = p\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(X = 0) = 1 - \\mathbb{P}(A) = 1 - p\n",
    "$$\n",
    "\n",
    "We say that $X$ follows **Bernoulli distribution** with parameter $p$ and write $X \\sim Be(p)$.\n",
    "\n",
    "We will call $\\mathbb{P}_X(\\omega)$ a **probability mass function** (PMF)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-connection",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bernoulli trial scheme\n",
    "\n",
    "Previously we have worked with independent events that were happening in one probability space. But sometimes we want to have multiple trials, where for every trial the probability space is known, but we are interested in the probability space covering all the trials at once. We can achieve it via direct product of probability spaces.\n",
    "\n",
    "If all probability spaces are the same and equal to:\n",
    "- $\\Omega = \\{0, 1\\}$\n",
    "- $\\mathcal{F} = \\{\\varnothing, 0, 1, \\Omega\\}$\n",
    "- $\\mathbb{P}(1) = p$ and $\\mathbb{P}(0) = 1 - p$\n",
    "\n",
    "Then we call such experiment a **Bernoulli trial scheme**, and the probability space of it is:\n",
    "- $\\Omega = \\{(i_1, \\ldots, i_n), i_j \\in \\{0, 1\\}\\}$\n",
    "- $\\mathcal{F} = 2^\\Omega$\n",
    "- $\\mathbb{P}(i_1, \\ldots, i_n) = p^{\\text{num} j \\text{ such that } i_j = 1} (1 - p)^{\\text{num} j \\text{ such that } i_j = 0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-league",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 6\n",
    "\n",
    "Consider $X_1, \\ldots, X_n \\sim Be(p)$ independent random variables. Then $Y = \\sum_{k=1}^n X_k$ follows **Binomial distribution** with parameters $n$ and $p$, $Y \\sim Bi(n, p)$. $\\mathbb{P}(Y = k) = ?$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-clinton",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 6\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(Y = k) = \\begin{pmatrix}n\\\\k\\end{pmatrix} p^k (1-p)^{n-k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-donor",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 7\n",
    "\n",
    "Consider $X$ and $Y$ independent $\\mathbb{Z}$-valued random variables. $\\mathbb{P}(X + Y = k) = ?$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-chancellor",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 7\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(X + Y = k) = \\sum_{m} \\mathbb{P}(X = m) \\mathbb{P}(Y = k - m)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-college",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 8\n",
    "\n",
    "Let $X \\sim Bi(n, p)$ and $Y \\sim Bi(m, p)$ be independent. What is the distribution of $Z = X + Y$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-member",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 8\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(X + Y = k) = \\sum_j \\begin{pmatrix}n\\\\j\\end{pmatrix} p^j (1-p)^{n-j} \\begin{pmatrix}m\\\\k-j\\end{pmatrix} p^{k-j} (1-p)^{m-k+j} = p^{k} (1-p)^{n+m-k} \\sum_j \\begin{pmatrix}n\\\\j\\end{pmatrix} \\begin{pmatrix}m\\\\k-j\\end{pmatrix} = \\begin{pmatrix}n+m\\\\k\\end{pmatrix} p^{k} (1-p)^{n+m-k}\n",
    "$$\n",
    "\n",
    "$$\n",
    "Z \\sim Bi(n+m, p)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-delaware",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cumulative distribution function\n",
    "\n",
    "Note that distribution of a discrete distribution of a random variable $X$ is uniquely defined by its PMF $\\mathbb{P}(X = x_i)$. In general, we define the distribution using cumulative distribution function (CDF):\n",
    "$$\n",
    "F_X(x) = \\mathbb{P}(X < x)\n",
    "$$\n",
    "\n",
    "It has the following properties:\n",
    "- $F_X$ is non-decreasing\n",
    "- $\\lim\\limits_{x\\to-\\infty}F_X(x) = 0$\n",
    "- $\\lim\\limits_{x\\to+\\infty}F_X(x) = 1$\n",
    "- $F_X$ if left continuous\n",
    "\n",
    "Interesting enough, the converse is also true. Any function that conforms to the properties above defines some probability distribution on $\\mathbb{R}$ and this relation is unique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-haiti",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probability density function\n",
    "\n",
    "- If $X$ has a discrete distribution, then $F_X$ has a countable number of jumps $p_i = \\mathbb{P}(X = x_i)$ and at $x = x_i$ it is continuous\n",
    "- If $X$ has absolutely continuous distribution, then $F_X$ is differentiable a.e. and can be recovered from its derivative:\n",
    "    $$\n",
    "    F_X(x) = \\int\\limits_{-\\infty}^x f_X(t) dt\n",
    "    $$\n",
    "    \n",
    "    where $f_X(t)$ is the probability density function and $f_X(t) = F'_X(x)$ a.e."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-chinese",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 9\n",
    "\n",
    "We say that random variable $X$ is distributed uniformly on $[a, b]$ and write $X \\sim U([a, b])$ if\n",
    "$$\n",
    "f_X(x) = \\begin{cases}\n",
    "\\frac{1}{b-a}, a \\leqslant x \\leqslant b, \\\\\n",
    "0, \\text{else}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-acrylic",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 10\n",
    "\n",
    "Consider $X$ and $Y$ independent random variables with PDFs $f_X$ and $f_Y$ respectively. Then, their sum $Z = X + Y$ has absolutely continuous distribution with density\n",
    "$$\n",
    "f_Z(z) = \\int f_X(x) f_Y(z-x) dx\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-minnesota",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 11\n",
    "\n",
    "Let $X, Y \\sim U([0, 1])$ and $Z = X + Y$. Find $f_Z(z)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-commerce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 11\n",
    "\n",
    "$$\n",
    "f_Z(z) = \\int\\limits_{0}^1 f_X(x) f_Y(z-x) dx = \\int\\limits_{0}^1 f_Y(z-x) dx = \\begin{cases}\n",
    "z, & 0 \\leqslant z \\leqslant 1, \\\\\n",
    "2 - z, & 1 \\leqslant z \\leqslant  2, \\\\\n",
    "0, & \\text{else}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-speaking",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Functions of random variables\n",
    "\n",
    "Random variables transform like functions, i.e. if $Y = \\varphi(X)$, then $Y(\\omega) = \\varphi(X(\\omega))$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-amazon",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 12\n",
    "\n",
    "Let $X$ be a random variable with CDF $F_X$ and PDF $f_X$. Find CDF and PDF of $Y = a X + b$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-bible",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 13\n",
    "\n",
    "If $a > 0$:\n",
    "$$\n",
    "F_Y(y) = \\mathbb{P}(Y < y) = \\mathbb{P}(a X + b < y) = \\mathbb{P}\\left(X < \\frac{y - b}{a}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "f_Y(y) = F'_Y(y) = \\frac{1}{|a|}f_X\\left(X < \\frac{y - b}{a}\\right)\n",
    "$$\n",
    "\n",
    "In general for a smooth $\\varphi$, the density will be:\n",
    "$$\n",
    "f_Y(y) = \\sum\\limits_{\\varphi(x) = y} \\frac{f_X(x)}{|\\varphi'(x)|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-motor",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 13\n",
    "\n",
    "Let $X$ be a **normally distributed** random variable with parameters $m$ and $\\sigma^2$:\n",
    "$$\n",
    "f_X(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left( - \\frac{(x - m)^2}{2\\sigma^2} \\right)\n",
    "$$\n",
    "\n",
    "Find PDF of $Y = X^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-seven",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 13"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
