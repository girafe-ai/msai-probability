{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8f7b639",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Seminar 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-example",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap of random variables\n",
    "\n",
    "Consider probabiliy space $(\\Omega, \\mathcal{F}, \\mathbb{P})$. A **random variable** is a measurable function $X: \\Omega \\to \\mathbb{R}$ from $(\\Omega, \\mathcal{F})$ to $(\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-durham",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Measurable function $X: \\Omega \\to \\mathbb{R}$ from $(\\Omega, \\mathcal{F})$ to $(\\mathbb{R}, \\mathcal{B}(\\mathbb{R}))$. It means that the pre-image of any set $A$ in $\\mathcal{B}(\\mathbb{R})$ belongs to $\\mathcal{F}$:\n",
    "$$\n",
    "\\forall A \\in \\mathcal{B}(\\mathbb{R}) \\Longrightarrow X^{-1}(A) \\in \\mathcal{F}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-malaysia",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap of distributions\n",
    "\n",
    "We will call the image $\\mu$ of measure $\\mathbb{P}$ through the mapping $X$ **the distribution** of r.v. $X$ and write $X \\sim \\mu$:\n",
    "$$\n",
    "\\mu(A) = \\mathbb{P}(X^{-1}(A))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-associate",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Any probabilistic measure (hence any probability distribution) can be decomposed into sum of three types of measures:\n",
    "- Discrete\n",
    "- Singular\n",
    "- Absolutely continuous\n",
    "\n",
    "Normally, the distributions fall into just one category and you never encounter singular distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-startup",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Functions describing distributions\n",
    "\n",
    "- For any distribution we have **cumulative distribution function** (CDF) $F_X(x) = \\mathbb{P}(X < x)$\n",
    "- For discrete distributions we have **probability mass function** (PMF) $\\mathbb{P}_X(x) = \\mathbb{P}(X = x)$\n",
    "- For continuous distributions we have **probability density function** (PDF) $f_X(x) = F'_X(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-speaking",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Functions of random variables\n",
    "\n",
    "Random variables transform like functions, i.e. if $Y = \\varphi(X)$, then $Y(\\omega) = \\varphi(X(\\omega))$.\n",
    "\n",
    "For a smooth $\\varphi$, the density will be:\n",
    "$$\n",
    "f_Y(y) = \\sum\\limits_{\\varphi(x) = y} \\frac{f_X(x)}{|\\varphi'(x)|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-divorce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mathematical expectation\n",
    "\n",
    "Mathematical expectation generalizes the concept of mean. Consider probability space $(\\Omega, \\mathcal{F}, \\mathbb{P})$ and random variable $X: \\Omega \\to \\mathbb{R}$. Then expected value of $X$ is\n",
    "$$\n",
    "\\mathbb{E}\\left[X\\right] = \\int_\\Omega X(\\omega) d\\mathbb{P}(\\omega) = \\int_{\\mathbb{R}} x d\\mu(x)\n",
    "$$\n",
    "\n",
    "- If $X$ is discrete, then\n",
    "    $$\n",
    "    \\mathbb{E}\\left[X\\right] = \\sum_k x_k \\mathbb{P}(X = x_k)\n",
    "    $$\n",
    "- If $X$ is continuous, then\n",
    "    $$\n",
    "    \\mathbb{E}\\left[X\\right] = \\int_{-\\infty}^{+\\infty} x f_X(x) dx\n",
    "    $$\n",
    "    \n",
    "It may be the case that $\\mathbb{E}\\left[X\\right] = \\pm \\infty$ or even does not exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-operator",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 1\n",
    "\n",
    "We roll a die and r.v. $X$ is the score of a roll. What is $\\mathbb{E}\\left[X\\right]$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-webcam",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 1\n",
    "\n",
    "$$\n",
    "\\mathbb{E}\\left[X\\right] = \\sum_{k=1}^6 k \\cdot \\mathbb{P}(X = k) = \\frac16 \\sum_{k=1}^6 k = \\frac72\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-feature",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 2\n",
    "\n",
    "We flip a non-symmetric coin and $X$ is the r.v. for heads, $X \\sim Be(p)$. What is $\\mathbb{E}\\left[X\\right]$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-lemon",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 2\n",
    "\n",
    "$$\n",
    "\\mathbb{E}\\left[X\\right] = 0 \\cdot \\mathbb{P}(X = 0) + 1 \\cdot \\mathbb{P}(X = 1) = p\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-topic",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 3\n",
    "\n",
    "Consider discrete r.v. $X$ with distribution $\\mathbb{P}(X = 2^n) = 2^{-n}$. What is $\\mathbb{E}\\left[X\\right]$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-syria",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 3\n",
    "\n",
    "$$\n",
    "\\mathbb{E}\\left[X\\right] = \\sum_{n} 2^n 2^{-n} = \\infty\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-bookmark",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 4\n",
    "\n",
    "Consider discrete r.v. $X$ with distribution $\\mathbb{P}(X = 2^n) = \\mathbb{P}(X = - 2^n) = 2^{-n-1}$. What is $\\mathbb{E}\\left[X\\right]$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-partnership",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 4\n",
    "\n",
    "Expectation of r.v. $X$ exists if and only if $\\mathbb{E}\\left[|X|\\right] < \\infty$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-revolution",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 5\n",
    "\n",
    "Consider $X$ with **Poisson distribution** $X \\sim Pois(\\lambda)$:\n",
    "$$\n",
    "\\mathbb{P}(X = k) = \\frac{\\lambda^k}{k!} e^{-\\lambda}\n",
    "$$\n",
    "\n",
    "What is $\\mathbb{E}\\left[X\\right]$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-lighter",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 5\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}\\left[X\\right] & = \\sum_{k=0}^\\infty k \\frac{\\lambda^k}{k!} e^{-\\lambda} = e^{-\\lambda} \\sum_{k=0}^\\infty k \\frac{\\lambda^k}{k!} = e^{-\\lambda} \\sum_{k=0}^\\infty \\frac{\\lambda^k}{(k - 1)!} = \\\\\n",
    "& = e^{-\\lambda} \\sum_{k=0}^\\infty \\frac{\\lambda^k}{(k - 1)!} = e^{-\\lambda} \\sum_{k=1}^\\infty \\frac{\\lambda^{k+1}}{k!} = \\lambda e^{-\\lambda} e^\\lambda = \\lambda\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-jurisdiction",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Properties of expectation\n",
    "\n",
    "Consider r.v.s $X$ and $Y$ with finite expectations. Then,\n",
    "1. For any constants $a$ and $b$ it holds $\\mathbb{E}\\left[aX + b\\right] = a \\mathbb{E}\\left[X\\right] + b$\n",
    "2. $\\mathbb{E}\\left[X + Y\\right] = \\mathbb{E}\\left[X\\right] + \\mathbb{E}\\left[Y\\right]$\n",
    "3. If $X \\leqslant Y$ a.s., then $\\mathbb{E}\\left[X\\right] \\leqslant \\mathbb{E}\\left[Y\\right]$\n",
    "4. If $X \\perp Y$, then $\\mathbb{E}\\left[XY\\right] = \\mathbb{E}\\left[X\\right] \\mathbb{E}\\left[Y\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-gibraltar",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 6\n",
    "\n",
    "Consider $X$ with binomial distribution $X \\sim Bi(n, p)$. What is $\\mathbb{E}\\left[X\\right]$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-mention",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 6\n",
    "\n",
    "- We know that $X = \\sum_{k=1}^n X_k$, where $X_k \\sim Be(p)$\n",
    "- We know that $\\mathbb{E}\\left[X_k\\right] = p$\n",
    "- Then, $\\mathbb{E}\\left[X\\right] = \\sum_{k=1}^n \\mathbb{E}\\left[X_k\\right] = np$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-campbell",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Expectation of a function of a random variable\n",
    "\n",
    "Consider $Y = \\varphi(X)$, then its expectation is\n",
    "$$\n",
    "\\mathbb{E}\\left[Y\\right] = \\int_\\Omega \\varphi(X(\\omega)) d \\mathbb{P}_X(\\omega) = \\int_{-\\infty}^\\infty \\varphi(x) d\\mu(x)\n",
    "$$\n",
    "\n",
    "If additionally the following integral exists\n",
    "$$\n",
    "\\int_{-\\infty}^\\infty |\\varphi(x)| d F_X(x) < \\infty\n",
    "$$\n",
    "\n",
    "Then,\n",
    "$$\n",
    "\\mathbb{E}\\left[Y\\right] = \\int_{-\\infty}^\\infty \\varphi(x) f_X(x) d x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-scoop",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Variance\n",
    "\n",
    "We call **variance** the following quantity of a r.v. $X$ with finite expectation:\n",
    "$$\n",
    "\\mathbb{V}\\text{ar}(X) = \\mathbb{E}\\left[\\left(X - \\mathbb{E}[X]\\right)^2\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-ethiopia",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 7\n",
    "\n",
    "We flip a non-symmetric coin and $X$ is the r.v. for heads, $X \\sim Be(p)$. What is $\\mathbb{V}\\text{ar}\\left(X\\right)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-nirvana",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 7\n",
    "\n",
    "1. We know the formula\n",
    "    $$\n",
    "    \\mathbb{V}\\text{ar}\\left(X\\right) = \\mathbb{E}\\left[\\left(X - \\mathbb{E}\\left[X\\right]\\right)^2\\right]\n",
    "    $$\n",
    "2. We know $\\mathbb{E}\\left[X\\right]$\n",
    "    $$\n",
    "    \\mathbb{V}\\text{ar}\\left(X\\right) = \\mathbb{E}\\left[\\left(X - p\\right)^2\\right] = \\mathbb{E}\\left[X^2 - 2 p X + p^2\\right]\n",
    "    $$\n",
    "3. We know that expectation is linear\n",
    "    $$\n",
    "    \\mathbb{V}\\text{ar}\\left(X\\right) = \\mathbb{E}\\left[X^2\\right] - 2 p \\mathbb{E}\\left[X\\right] + p^2 = \\mathbb{E}\\left[X^2\\right] - p^2\n",
    "    $$\n",
    "4. For $Y = X^2$ we can compute\n",
    "    $$\n",
    "    \\mathbb{E}\\left[Y\\right] = 0 \\cdot \\mathbb{P}(Y = 0) + 1 \\cdot \\mathbb{P}(Y = 1) = \\mathbb{P}(Y = 1) = \\mathbb{P}(X^2 = 1) = \\mathbb{P}(X = 1) = p\n",
    "    $$\n",
    "5. Finally,\n",
    "    $$\n",
    "    \\mathbb{V}\\text{ar}\\left(X\\right) = p - p^2 = p (1 - p)\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-instruction",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Properties of variance\n",
    "\n",
    "1. $\\mathbb{V}\\text{ar}\\left(X\\right) \\geqslant 0$ and $\\mathbb{V}\\text{ar}\\left(X\\right) = 0$ if and only if $X = const$ a.s.\n",
    "2. If holds\n",
    "    $$\n",
    "    \\mathbb{V}\\text{ar}\\left(X\\right) = \\mathbb{E}\\left[X^2\\right] - \\left(\\mathbb{E}\\left[X\\right]\\right)^2\n",
    "    $$\n",
    "3. It holds\n",
    "    $$\n",
    "    \\mathbb{V}\\text{ar}\\left(aX + b\\right) = b^2 \\mathbb{V}\\text{ar}\\left(X\\right)\n",
    "    $$\n",
    "4. If $X \\perp Y$, it holds\n",
    "$$\n",
    "\\mathbb{V}\\text{ar}\\left(X + Y\\right) = \\mathbb{V}\\text{ar}\\left(X\\right) + \\mathbb{V}\\text{ar}\\left(Y\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-happiness",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 8\n",
    "\n",
    "Consider $X$ with binomial distribution $X \\sim Bi(n, p)$. What is $\\mathbb{V}\\text{ar}\\left(X\\right)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-execution",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 8\n",
    "\n",
    "- We know that $X = \\sum_{k=1}^n X_k$, where $X_k \\sim Be(p)$\n",
    "- We know that $\\mathbb{V}\\text{ar}\\left(X_k\\right) = p(1-p)$\n",
    "- Then, $\\mathbb{V}\\text{ar}\\left(X\\right) = \\mathbb{V}\\text{ar}\\left(\\sum_{k=1}^n X_k\\right) = \\sum_{k=1}^n \\mathbb{V}\\text{ar}\\left(X_k\\right) = np(1-p)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-immigration",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Moments of distribution\n",
    "\n",
    "$\\mathbb{E}\\left[X^k\\right]$ is called $k$-th moment of r.v. $X$.\n",
    "\n",
    "We say that $k$-th moment is finite if $\\mathbb{E}\\left[X^k\\right] < \\infty$.\n",
    "\n",
    "If $k$-th moment is finite, then all moments $m < k$ are finite as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-narrative",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Jensen's inequality\n",
    "\n",
    "Consider r.v. $X$ with $\\mathbb{E}[X] < \\infty$ and convex function $g(\\cdot)$, then\n",
    "$$\n",
    "\\mathbb{E}\\left[g(X)\\right] \\geqslant g\\left(\\mathbb{E}\\left[X\\right]\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-athletics",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 9\n",
    "\n",
    "Prove Jensen's inequality for special case of $g(x) = x^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-attraction",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cauchy-Schwarz inequality\n",
    "\n",
    "Consider r.v. $X$ with $\\mathbb{E}\\left[X^2\\right] < \\infty$, then\n",
    "$$\n",
    "|\\mathbb{E}\\left[XY\\right]| \\leqslant \\sqrt{\\mathbb{E}\\left[X^2\\right]\\mathbb{E}\\left[Y^2\\right]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-diamond",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Covariance\n",
    "\n",
    "**Covariance** of two random variables $X$ and $Y$ is defined as\n",
    "$$\n",
    "\\operatorname{cov}\\left(X, Y\\right) = \\mathbb{E}\\left[\\left(X - \\mathbb{E}\\left[X\\right]\\right)\\left(Y - \\mathbb{E}\\left[Y\\right]\\right)\\right] = \\mathbb{E}\\left[XY\\right] - \\mathbb{E}\\left[X\\right]\\mathbb{E}\\left[Y\\right]\n",
    "$$\n",
    "\n",
    "From Cauchy-Schwarz inequality,\n",
    "$$\n",
    "\\operatorname{cov}\\left(X, Y\\right) \\leqslant \\sqrt{\\mathbb{V}\\text{ar}\\left(X\\right)\\mathbb{V}\\text{ar}\\left(Y\\right)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prostate-promise",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Correlation\n",
    "\n",
    "If $X \\perp Y$, $\\operatorname{cov}\\left(X, Y\\right) = 0$. The converse is not true. Regardless, covariance is often used to measure the dependency between random variables. It is not handy to use, so instead a **correlation coefficient** is proposed:\n",
    "$$\n",
    "r_{XY} = \\frac{\\operatorname{cov}\\left(X, Y\\right)}{\\sqrt{\\mathbb{V}\\text{ar}\\left(X\\right)\\mathbb{V}\\text{ar}\\left(Y\\right)}}\n",
    "$$\n",
    "\n",
    "Note that $-1 \\leqslant r_{XY} \\leqslant 1$."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
