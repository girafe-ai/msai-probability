{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f9a4edb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64f0689",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Examples of transformations\n",
    "\n",
    "- Linear transformations of random variables and vectors $Y = aX + b$\n",
    "- Non-linear invertible transformations of random variables $Y = g(X)$\n",
    "- Sums $Y = X_1 + X_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aba036",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformations previously\n",
    "\n",
    "We have a technique for computing the expectation of transformed random variable. What is its name?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02823f4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "LOTUS:\n",
    "$$\n",
    "\\mathbb{E}[g(X)] = \\sum_{x} g(x) \\mathbb{P}(X = x)\n",
    "$$\n",
    "It works with continuous r.v.s:\n",
    "$$\n",
    "\\mathbb{E}[g(X)] = \\int g(x) f_X(x) dx\n",
    "$$\n",
    "And it works in multiple dimensions:\n",
    "$$\n",
    "\\mathbb{E}[g(X, Y)] = \\sum_{x} \\sum_{y} g(x, y) \\mathbb{P}(X = x, Y = y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ec38b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transformations now\n",
    "\n",
    "Now we want not just the expected value, but the whole distribution (CDF, PMF, PDF). The approach depends on whether the distribution is discrete or continuous.\n",
    "\n",
    "## Discrete case\n",
    "\n",
    "The formula:\n",
    "$$\n",
    "\\mathbb{P}(g(X) = y) = \\sum\\limits_{x \\text{ such that } g(x) = y} \\mathbb{P}(X = x)\n",
    "$$\n",
    "\n",
    "If $g(\\cdot)$ is one-to-one, it simplifies to:\n",
    "$$\n",
    "\\mathbb{P}(g(X) = y) = \\mathbb{P}(X = g^{-1}(y))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300d0052",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 1\n",
    "\n",
    "Let $X \\sim Bin(n, p)$. Find the PDF of $Y = \\exp(X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d0ef6a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 1\n",
    "\n",
    "So $g(x) = \\exp(x)$, it's one-to-one and the inverse is $g^{-1}(x) = \\log x$.\n",
    "$$\n",
    "\\mathbb{P}(Y = y) = \\mathbb{P}(X = g^{-1}(y)) =  \\mathbb{P}(X = \\log y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a5036d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Continuous case\n",
    "\n",
    "In the continuous case, when additionally $g(\\cdot)$ is one-to-one, continuous and strictly increasing, we have the following relation for CDF:\n",
    "$$\n",
    "F_{g(X)}(y) = \\mathbb{P}(g(X) \\leqslant y) = \\mathbb{P}(X \\leqslant g^{-1}(y)) = F_X(g^{-1}(y))\n",
    "$$\n",
    "\n",
    "To get the PDF, we need to differentiate this relation at every point with the chain rule:\n",
    "$$\n",
    "f_{g(X)}(g(x)) d \\left( g(x) \\right) = f_X(x) dx\n",
    "$$\n",
    "\n",
    "To account for the case when $g(\\cdot)$ is strictly decreasing, we add the modulus\n",
    "$$\n",
    "f_{g(X)}(g(x)) = f_X(x) \\left| \\frac{d g(x)}{dx} \\right|^{-1}\n",
    "$$\n",
    "\n",
    "This is called 1D change of variables formula. Similarly to sicrete case, we can extend it to non one-to-one $g(\\cdot)$ using the sum over $x$ such that $g(x) = y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e348fcf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 2\n",
    "\n",
    "Let $X \\sim Exp(1)$. Find the PDF of $Y = \\exp(- X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae1360",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 2\n",
    "\n",
    "So $g(x) = \\exp(- x)$, it is one-to-one, and $g^{-1}(y) = - \\log y$. Let's find\n",
    "$$\n",
    "\\frac{dg(x)}{dx} = - \\exp(- x)\n",
    "$$\n",
    "\n",
    "So,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f_Y(y) & = f_X(x) \\left| \\frac{d g(x)}{dx} \\right|^{-1} = f_X(- \\log y) \\exp (x) = \\\\\n",
    "& = f_X(- \\log y) \\exp (- \\log y) = \\frac1y f_X(- \\log y)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8d9aaa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 3\n",
    "\n",
    "Let $X \\sim \\mathcal{N}(0, 1)$. Find the PDF of $Y = X^2$. This distribution is called chi-square distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22365b9b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 3\n",
    "\n",
    "So, $g(x) = x^2$. It is not one-to-one, so we need the sum:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f_Y(y) & = \\sum_{x = \\{-\\sqrt{y}, \\sqrt{y}\\}} f_X(x) \\left| \\frac{d g(x)}{dx} \\right|^{-1} = \\sum_{x = \\{-\\sqrt{y}, \\sqrt{y}\\}} f_X(x) 2 x = \\\\& = f_X(\\sqrt{y}) \\frac{1}{2 \\sqrt{y}} + f_X(- \\sqrt{y}) \\frac{1}{2 \\sqrt{y}} = \\\\\n",
    "& = 2 f_X(\\sqrt{y}) \\frac{1}{2 \\sqrt{y}}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efaa28e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 4\n",
    "\n",
    "Let $X$ be a random variable with PDF $f_X$. Find PDF of $Y = a X + b$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a1da9b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 4\n",
    "\n",
    "So, $g(x) = ax+b$, it is one-to-one, and the inverse is $g^{-1}(y) = \\frac1a (y - b)$. We need to calculate\n",
    "$$\n",
    "\\frac{dg(x)}{dx} = \\frac{d(ax + b)}{dx} = a\n",
    "$$\n",
    "\n",
    "$$\n",
    "f_Y(y) = f_X(x) \\left| \\frac{d g(x)}{dx} \\right|^{-1} = f_X\\left(\\frac{y - b}{a}\\right) \\frac{1}{|a|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29d8da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multivariate transformations\n",
    "\n",
    "Consider $n$-dimensional random vector $X \\in \\mathbb{R}^n$ with continuous distribution with PDF $f_X$. Let $g: A_0 \\to B_0$ be invertive one-to-one function from open subset $A_0$ containing support of $X$ to an open subset $B_0$ containing the range of $g(\\cdot)$. Denote $Y = g(X)$ and $y = g(x)$. Suppose that all partial derivatives $\\frac{\\partial y_i}{\\partial x_j}$ exist and are continuous. Then, we can form the Jacobian matrix:\n",
    "$$\n",
    "\\frac{\\partial y}{\\partial x} = \\left(\\begin{array}{cccc}\n",
    "\\frac{\\partial y_1}{\\partial x_1} & \\frac{\\partial y_1}{\\partial x_2} & \\ldots & \\frac{\\partial y_1}{\\partial x_n} \\\\\n",
    "\\vdots & & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial y_n}{\\partial x_1} & \\frac{\\partial y_n}{\\partial x_2} & \\ldots & \\frac{\\partial y_n}{\\partial x_n}\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febb4184",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Assume that this matrix is non-degenerate. Then, the PDF of $Y$ is:\n",
    "$$\n",
    "f_Y(y) = f_X(g^{-1}(y)) \\left|\\det \\frac{\\partial y}{\\partial x}\\right|^{-1}\n",
    "$$\n",
    "\n",
    "If the function is not one-to-one, we add sum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ba0b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 5\n",
    "\n",
    "Consider $n$-dimensional random vector $X \\in \\mathbb{R}^n$ with continuous distribution, a non-degenerate matrix $A \\in \\mathbb{R}^{m \\times n}$ and a vector $b \\in \\mathbb{R}^m$, then define random vector $Y = AX + b$. What is the expected value, the covariance matrix and the PDF of $Y$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca0cf2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 5\n",
    "\n",
    "Its expected value will be $\\mathbb{E}[Y] = A \\mathbb{E} [X] + b$ and its covariance matrix will be:\n",
    "$$\n",
    "\\Sigma_Y = \\mathbb{E}\\left[(AX - A \\mathbb{E}[X]) (AX - A \\mathbb{E}[X])^\\top\\right] = A \\mathbb{E}\\left[(X - \\mathbb{E}[X]) (X - \\mathbb{E}[X])^\\top\\right] A^\\top = A \\Sigma_X A^\\top\n",
    "$$\n",
    "\n",
    "So,\n",
    "- $g(x) = Ax + b$\n",
    "- $\\frac{\\partial y}{\\partial x} = A$\n",
    "- $g^{-1}(y) = A^{-1} (y - b)$\n",
    "\n",
    "Therefore,\n",
    "$$\n",
    "f_Y(y) = f_X(g^{-1}(y)) \\left|\\det \\frac{\\partial y}{\\partial x}\\right|^{-1} = f_X(A^{-1}(y - b)) \\frac{1}{|\\det A|} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e55a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 6\n",
    "\n",
    "Consider $n$ independent standard normal r.v.s $X_1, \\ldots, X_n \\sim \\mathcal{N}(0, 1)$ and vector $X = (X_1, \\ldots, X_n)^\\top$. We know that\n",
    "- $\\mathbb{E}[X] = 0$\n",
    "- $\\Sigma_X = I$\n",
    "- $f_X(x) = (2 \\pi)^{- n/2} \\exp(- \\frac12 x^\\top x)$\n",
    "\n",
    "Consider a non-degenerate matrix $A \\in \\mathbb{R}^{n\\times n}$ and $Y = AX + m$. Find its expectation, covariance matrix and distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b90512",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 6\n",
    "\n",
    "From the previous example, $\\mathbb{E}[Y] = m$ and $\\Sigma_Y = AA^\\top$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f_X(x) & = f_X(A^{-1}(y - m)) \\frac{1}{|\\det A|} = \\\\\n",
    "& = \\frac{1}{(2 \\pi)^{n/2} |\\det A|} \\exp \\left( - \\frac{(y - m)^\\top A^{-\\top} A^{-1} (y - m)}{2} \\right) = \\\\\n",
    "& = \\frac{1}{(2 \\pi)^{n/2} \\sqrt{\\det \\Sigma_Y}} \\exp \\left( - \\frac{(y - m)^\\top \\Sigma_Y^{-1} (y - m)}{2} \\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "What we just did, is we obtained a new random normal vector with controllable parameters from a standard normal random vector. This is a very useful property of a random normal vectors, but also demonstrates the power of linear transforms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3cb2d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 7\n",
    "\n",
    "Let random vector $(X, Y)$ have PDF $f_{X, Y}(x, y)$. Find the density of $Z = X + Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99217cb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 7\n",
    "\n",
    "In order to find this density, consider transform\n",
    "$$\n",
    "\\begin{pmatrix}Z\\\\Y\\end{pmatrix} = A \\begin{pmatrix}X\\\\Y\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "So, matrix $A$ is...?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800ad1a5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "A = \\begin{pmatrix}1&1\\\\0&1\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8a4781",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then,\n",
    "$$\n",
    "f_{Z,Y}(z,y) = f_{X,Y}(A^{-1}(x \\; y)^\\top, y) \\left|\\det A\\right|^{-1} = f_{X,Y}(z-y,y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20094347",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally,\n",
    "$$\n",
    "f_Z(z) = \\int f_{Z,Y}(z,y) dy = \\int f_{X,Y}(z-y,y) dy\n",
    "$$\n",
    "\n",
    "If $X \\perp Y$,\n",
    "$$\n",
    "f_Z(z) = \\int f_{X}(z-y) f_Y(y) dy\n",
    "$$\n",
    "\n",
    "This is the convolution rule that we studied on Seminar 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af673e63",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convolution rule\n",
    "\n",
    "Consider independent r.v.s $X$ and $Y$. Then, their sum $Z = X + Y$ is distributed:\n",
    "- If they are discrete,\n",
    "    $$\n",
    "    \\mathbb{P}(Z = n) = \\sum_{k=-\\infty}^\\infty \\mathbb{P}(X = k) \\mathbb{P}(Y = n-k)\n",
    "    $$\n",
    "- If they are continuous,\n",
    "    $$\n",
    "    f_Z(z) = \\int_{-\\infty}^\\infty f_X(z-y) f_Y(y) dy\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba91eff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 8\n",
    "\n",
    "Let $X \\sim Bi(n, p)$ and $Y \\sim Bi(m, p)$ be independent. What is the distribution of $Z = X + Y$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef82a7ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 8\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{P}(X + Y = k) & = \\sum_j \\begin{pmatrix}n\\\\j\\end{pmatrix} p^j (1-p)^{n-j} \\begin{pmatrix}m\\\\k-j\\end{pmatrix} p^{k-j} (1-p)^{m-k+j} = \\\\\n",
    "& = p^{k} (1-p)^{n+m-k} \\sum_j \\begin{pmatrix}n\\\\j\\end{pmatrix} \\begin{pmatrix}m\\\\k-j\\end{pmatrix} = \\\\\n",
    "& =\\begin{pmatrix}n+m\\\\k\\end{pmatrix} p^{k} (1-p)^{n+m-k}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "Z \\sim Bi(n+m, p)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7997e355",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 9\n",
    "\n",
    "Let $X, Y \\sim Exp(1)$ be independent. Find the PDF of $Z = \\frac{X}{X+Y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85532bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 9\n",
    "\n",
    "This one will be a non-linear transform. Consider transform $(X, Y) \\to (Z, U)$, where $U = X + Y$. The inverse transform is $X = UZ, Y = U - UZ$. Jacobian of the inverse transform is\n",
    "$$\n",
    "\\frac{\\partial (x, y)}{\\partial (z, u)} = \\begin{pmatrix}u&z\\\\-u&1-z\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "The joint density is\n",
    "$$\n",
    "    f_{Z, U}(z, u) =  f_{X, Y}(g^{-1}(z, u)) \\left|\\det \\frac{\\partial (x, y)}{\\partial (z, u)}\\right| = f_{X, Y}(uz, u-uz) u = ue^u, u > 0, 0 < z \\leqslant 1\n",
    "$$\n",
    "\n",
    "The joint density does not depend on $z$, it means that marginal density of $Z$ is Uniform with support $[0, 1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ea168e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Homework problems\n",
    "\n",
    "1. Compute the moment-generating function of $Geom(p)$. Use it to find expectation and variance.\n",
    "2. Let $X$ and $Y$ be i.i.d. $Geom(p)$, and $N = X + Y$. Find the joint PMF of $X, Y, N$. Find the joint PMF of $X$ and $N$. Find the conditional PMF of $X$ given $N = n$\n",
    "3. Let $U \\sim U[0, \\tfrac{\\pi}{2}]$. Find the PDF of $\\sin(U)$.\n",
    "4. Let $X$ and $Y$ be i.i.d. $Exp(\\lambda)$, and $T = \\log(X/Y)$. Find the CDF and PDF of $T$."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Слайд-шоу",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
