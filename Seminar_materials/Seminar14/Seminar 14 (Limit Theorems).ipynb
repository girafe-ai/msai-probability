{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2255baed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Inequalities recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19842ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inequalities recap\n",
    "\n",
    "|Name|Conditions|Formula|Uses|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|Cauchy-Schwarz|\\begin{eqnarray}\\mathbb{E}[|X|]<\\infty, \\mathbb{E}[|Y|]<\\infty\\end{eqnarray}|\\begin{eqnarray}|\\mathbb{E}[XY]|\\leqslant\\sqrt{\\mathbb{E}[X]\\mathbb{E}[Y]}\\end{eqnarray}|Covariance|\n",
    "|Jensen|\\begin{eqnarray}\\mathbb{E}[|X|]<\\infty, x>0, g - \\text{convex}\\end{eqnarray}|\\begin{eqnarray}g(\\mathbb{E}[X])\\leqslant\\mathbb{E}[g(X)]\\end{eqnarray}|Proofs|\n",
    "|Markov|\\begin{eqnarray}\\mathbb{E}[|X|^p]<\\infty, p>0, x>0\\end{eqnarray}|\\begin{eqnarray}\\mathbb{P}(|X| \\geqslant x) \\leqslant \\frac{\\mathbb{E}[|X|^p]}{x^p}\\end{eqnarray}|Tails|\n",
    "|Chebyshev|\\begin{eqnarray}\\mathbb{V}\\text{ar}(X)<\\infty, x>0\\end{eqnarray}|\\begin{eqnarray}\\mathbb{P}(|X - \\mathbb{E}[X]| \\geqslant x) \\leqslant \\frac{\\mathbb{V}\\text{ar}(X)}{x^2}\\end{eqnarray}|Tails|\n",
    "|Chernoff|\\begin{eqnarray}\\mathbb{E}[e^{tX}]<\\infty,t>0,x>0\\end{eqnarray}|\\begin{eqnarray}\\mathbb{P}(X \\geqslant x) \\leqslant \\frac{\\mathbb{E}[e^{tX}]}{e^{tx}}\\end{eqnarray}|Tails|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e171c83",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Homework problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5f954d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 1\n",
    "\n",
    "In a national survey, a random sample of people are chosen and asked whether they support a certain policy. Assume that everyone in the population is equally likely to be surveyed at each step, and that the sampling is with replacement (sampling without replacement is typically more realistic, but with replacement will be a good approximation if the sample size is small compared to the population size). Let $n$ be the sample size, and let $\\hat{p}$ and $p$ be the proportion of people who support the policy in the sample and in the entire population, respectively. Show that for every $c > 0$,\n",
    "$$\n",
    "\\mathbb{P}(|\\hat{p} - p| > c\\sigma) \\leqslant \\frac{1}{4nc^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa5b773",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 1\n",
    "\n",
    "Let $X \\sim Bin(n, p)$ describe the number of people, who support the policy. Then,\n",
    "$$\n",
    "\\hat{p} = \\frac{X}{n}\n",
    "$$\n",
    "\n",
    "Then,\n",
    "$$\n",
    "\\mathbb{E}[\\hat{p}] = \\frac{1}{n}\\mathbb{E}[X] = \\frac{1}{n}np = p\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbb{V}\\text{ar}(\\hat{p}) = \\frac{1}{n^2}\\mathbb{V}\\text{ar}(X) = \\frac{p(1-p)}{n}\n",
    "$$\n",
    "\n",
    "Then we use Chebyshev inequality\n",
    "$$\n",
    "\\mathbb{P}(|\\hat{p} - \\mathbb{E}[\\hat{p}]| > c) \\leqslant \\frac{\\mathbb{V}\\text{ar}(\\hat{p})}{c^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(|\\hat{p} - p| > c) \\leqslant \\frac{p(1-p)}{nc^2} \\leqslant \\frac{1}{4nc^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe77da7f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convergence of random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57401c7b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convergence of random variables\n",
    "\n",
    "Consider infinite series of r.v.s $X_1, X_2, \\ldots$\n",
    "\n",
    "1. $X_n$ converges to $X$ **in probability** ($X_n \\xrightarrow{P} X$) if $\\forall \\varepsilon > 0$\n",
    "    $$\n",
    "    \\mathbb{P}(|X_n - X| > \\varepsilon) \\to 0\n",
    "    $$\n",
    "2. $X_n$ converges to $X$ **almost surely** ($X_n \\xrightarrow{\\text{a.s.}} X$) if\n",
    "    $$\n",
    "    \\mathbb{P}(X_n \\to X) = 1\n",
    "    $$\n",
    "3. $X_n$ converges to $X$ **mean-square** ($X_n \\xrightarrow{\\text{m.s.}} X$) if\n",
    "    $$\n",
    "    \\mathbb{E}\\left[(X_n - X)^2\\right] \\to 0\n",
    "    $$\n",
    "4. $X_n$ converges to $X$ **in distribution** ($X_n \\xrightarrow{d} X$) if for any bounded continuous function $\\varphi$\n",
    "    $$\n",
    "    \\mathbb{E}[\\varphi(X_n)] \\to \\mathbb{E}[\\varphi(X)]\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958619c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Convergence in probability, detailed\n",
    "\n",
    "- $X_n \\xrightarrow{d} X$ is equivalent to $F_{X_n}(x) \\to F_X(x)$\n",
    "- If r.v. takes only integer values, then $X_n \\xrightarrow{d} X$ is equivalent to $\\mathbb{P}(X_n = k) \\to \\mathbb{P}(X = k)$\n",
    "- $X_n \\xrightarrow{d} X$ is equivalent to convergence of characteristic functions, PGFs, MGFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b18466",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 1\n",
    "\n",
    "Let $X_n \\sim Bin(n, p_n)$ and $np_n \\to \\lambda, n \\to \\infty$. Show that $X_n \\xrightarrow{d} X \\sim Pois(\\lambda)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af91ee58",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 1\n",
    "\n",
    "We need to show $\\mathbb{P}(X_n = k) \\to \\mathbb{P}(X = k)$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{P}(X_n = k) & = \\begin{pmatrix}n\\\\k\\end{pmatrix} p^k (1 - p)^{n-k} = \\frac{n(n-1)\\ldots (n-k+1)}{k!} \\left( \\frac{\\lambda}{n} \\right)^k \\left( 1 - \\frac{\\lambda}{n} \\right)^n \\left( 1- \\frac{\\lambda}{n} \\right)^{-k} = \\\\\n",
    "& = \\left[ \\frac{\\lambda^k}{k!} \\underbrace{\\left(1- \\frac{\\lambda}{n} \\right)^n}_{\\to e^{-\\lambda}} \\right] \\underbrace{\\left( 1 - \\frac{\\lambda}{n} \\right)^{-k}}_{\\to 1} \\underbrace{\\frac{n(n-1)\\ldots (n-k+1)}{n^k}}_{\\to 1} \\to \\frac{\\lambda^k}{k!} e^{-\\lambda} = \\\\\n",
    "& = \\mathbb{P}(X = k)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3e36dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Relations between types of convergence\n",
    "\n",
    "1. $X_n \\xrightarrow{P} X \\Rightarrow X_n \\xrightarrow{d} X$\n",
    "2. $X_n \\xrightarrow{\\text{a.s.}} X \\Rightarrow X_n \\xrightarrow{P} X$\n",
    "3. $X_n \\xrightarrow{\\text{m.s.}} X \\Rightarrow X_n \\xrightarrow{P} X$\n",
    "4. If $\\{X_n\\}$ is monotonic a.s. ($X_{n+1} \\geqslant X_n$ a.s.) $X_n \\xrightarrow{P} X \\Rightarrow X_n \\xrightarrow{\\text{m.s.}} X$\n",
    "5. If $X_n$ is uniformly bounded ($|X_n| < a$ a.s.) $X_n \\xrightarrow{P} X \\Rightarrow X_n \\xrightarrow{\\text{m.s.}} X$\n",
    "5. $X_n \\xrightarrow{d} C \\Rightarrow X_n \\xrightarrow{P} C$\n",
    "\n",
    "<img align=\"center\" src=\"convergence_relations.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3899d533",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Limit theorems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ed877f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Limit theorems\n",
    "\n",
    "We will discuss the two most famous theorems in probability:\n",
    "- the law of large numbers (LLN)\n",
    "- the central limit theorem (CLT)\n",
    "\n",
    "Both tell us what happens to the **sample mean** $\\overline{X_n} = \\frac1n \\sum_{i=1}^n X_i$ as we obtain more and more data $n \\to \\infty$.\n",
    "\n",
    "Limit theorems let us make approximations which are likely to work well when we have a large number of data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c837a36f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Law of large numbers\n",
    "\n",
    "Let $X_1, X_2, \\ldots, X_n$ be i.i.d. r.v.s with $\\mathbb{E}[X_i] = m$ and $\\mathbb{V}\\text{ar}(X) = \\sigma^2$. Then,\n",
    "$$\n",
    "\\mathbb{E}\\left[ \\left( \\frac1n \\sum_{i=1}^n X_i - m \\right)^2 \\right] \\to 0\n",
    "$$\n",
    "\n",
    "So, LLN says that\n",
    "$$\n",
    "\\frac1n \\sum_{i=1}^n X_i \\xrightarrow{\\text{m.s.}} m\n",
    "$$\n",
    "\n",
    "We know that m.s. convergence implies $P$-convergence, so\n",
    "$$\n",
    "\\frac1n \\sum_{i=1}^n X_i \\xrightarrow{P} m\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88bd73b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Law of large numbers\n",
    "\n",
    "1. (Chebyshev form) The i.i.d. part can be relaxed to $\\operatorname{cov}(X_i, X_j) \\leqslant 0$\n",
    "2. (Khinchin form) The existence of variance can be relaxed, but then we only have convergence in probability\n",
    "3. Both parts can not be relaxed at the same time\n",
    "4. Existence of expectation is essential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3078a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Strong law of large numbers\n",
    "\n",
    "Let $X_1, X_2, \\ldots, X_n$ be i.i.d. r.v.s with $\\mathbb{E}[X_i] = m$. Then,\n",
    "$$\n",
    "\\frac1n \\sum_{i=1}^n X_i \\xrightarrow{\\text{a.s.}} m\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239593c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 2\n",
    "\n",
    "Consider you have $K_1$ money, that you want to multiply. You have two possibilities to do that:\n",
    "- to put the money into the bank that guarantees $b \\cdot 100\\%$ yearly interest\n",
    "- to invest into stocks that will earn you $X \\cdot 100\\%$ yearly interest, where $X$ is an r.v. with expected value $m_X > b > 0$\n",
    "\n",
    "Denote the fraction of money put into the bank as $u$ and the fraction of money invested into stocks $v$, such that $0 \\leqslant u + v \\leqslant 1$. This way, in a year, you will have\n",
    "$$\n",
    "K_2 = K_1 (1 + bu + Xv)\n",
    "$$\n",
    "\n",
    "Obviously, the strategy maximizing the expected income is to set $u = 0, v = 1$. Show that \n",
    "- $\\mathbb{E}[K_t] \\to \\infty$\n",
    "- If $\\mathbb{E}[\\log (1 + X)] < 0$, then $\\mathbb{E}[K_t] \\xrightarrow{\\text{a.s.}} 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d6736",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 2.1\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[K_{t+1}] = \\mathbb{E}[K_t (1 + X_t)] = \\mathbb{E}[K_1 \\prod_{i=1}^t (1 + X_i)] = K_1 (1 + m_x)^t \\to \\infty\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e959c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 2.2\n",
    "\n",
    "Consider change of variables\n",
    "$$\n",
    "K_{t+1} = K_1 e^{tY_t}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "Y_t = \\frac1t \\sum_{i=1}^t \\log(1+ X_i)\n",
    "$$\n",
    "\n",
    "Consider SLLN for $\\log(1+ X_i)$, then\n",
    "$$\n",
    "\\frac1t \\sum_{i=1}^t \\log(1+ X_i) \\xrightarrow{\\text{a.s.}} \\mathbb{E}[\\log(1+ X)] = - a < 0\n",
    "$$\n",
    "\n",
    "Then,\n",
    "$$\n",
    "K_{t+1} = K_1 e^{-at} \\xrightarrow{\\text{a.s.}} 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79080c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Central limit theorem\n",
    "\n",
    "Let $X_1, X_2, \\ldots, X_n$ be i.i.d. r.v.s, $\\mathbb{E}[X] = \\mu$, $\\mathbb{V}\\text{ar}(X) = \\sigma^2$. Then,\n",
    "$$\n",
    "Z_n = \\frac{\\sum_{i=1}^n X_i - \\mu}{\\sqrt{n \\sigma^2}} \\xrightarrow{d} \\mathcal{N}(0, 1)\n",
    "$$\n",
    "\n",
    "If additionally $X_i$ are continuous, then\n",
    "$$\n",
    "f_{Z_n}(x) \\to \\frac{1}{\\sqrt{2\\pi}} e^{-x^2/2}\n",
    "$$\n",
    "\n",
    "It works for random vector as well. Let $\\mathbf{X_1}, \\mathbf{X_2}, \\ldots, \\mathbf{X_n}$ be i.i.d. with $\\mathbb{E}[\\mathbf{X}] = \\mathbf{m}$ and covariance matrix $\\Sigma$. Then,\n",
    "$$\n",
    "\\frac{\\sum_{i=1}^n \\mathbf{X_i} - \\mathbf{m}}{\\sqrt{n}} \\sim \\mathcal{N}(0, \\Sigma)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a0f686",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 3\n",
    "\n",
    "В выборах участвовали два кандидата T и C. T набрал NT = 520000 го- лосов, а C — NC = 480000. Оказалось, что аппарат считающий бюллетени, был настроен неправильно, и случайно менял каждый голос на противоположный с вероятностью p = 0.45. Найти вероятность того, что число голосов за T оказалось не меньше N T , если изначально за T и C было отдано поровну голосов: N0T = N0C = 500000.\n",
    "\n",
    "Two parties $L$ and $D$ participate in election. $L$ gets $N_L = 520000$ votes, $D$ gets $N_D = 480000$ votes. Turns out that the voting machine was broken and randomly changed a vote with probability $p = 0.45$. Find probability that votes for $L$ were at least $N_L$ if the actual votes were $N_{0L} = N_{0D} = 500000$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4cb1e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 3\n",
    "\n",
    "Consider r.v. $X_i \\sim Be(p)$ - indicator of error $D \\to L$, and $Y_i \\sim Be(p)$ - indicator of error $L \\to D$. Then, the votes for $L$ are\n",
    "$$\n",
    "Z = \\sum_{i=1}^{N_{0L}} X_i + \\sum_{j=1}^{N_{OD}} (1 - Y_j)\n",
    "$$\n",
    "\n",
    "By CLT,\n",
    "$$\n",
    "\\frac{Z - \\mathbb{E}[Z]}{\\sqrt{N_{OD}\\mathbb{V}\\text{ar}(X_i)}} \\sim \\mathcal{N}(0, 1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[Z] = N_{0L} p + N_{OD} (1-p) = N_{OD}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbb{V}\\text{ar}(X_i) = p (1 - p)\n",
    "$$\n",
    "\n",
    "Then,\n",
    "$$\n",
    "\\mathbb{P}(Z \\geqslant N_L) = \\mathbb{P}\\left(\\frac{Z - N_{OD}}{\\sqrt{2 N_{OD} p (1 - p)}} \\geqslant \\frac{N_L - N_{OD}}{\\sqrt{2 N_{OD} p (1 - p)}}\\right) \\approx \\mathbb{P}(V \\geqslant a)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be46233",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 3\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(Z \\geqslant N_L) = \\mathbb{P}\\left(\\frac{Z - N_{OD}}{2 N_{OD} p (1 - p)} \\geqslant \\frac{N_L - N_{OD}}{2 N_{OD} p (1 - p)}\\right) \\approx \\mathbb{P}(V \\geqslant a)\n",
    "$$\n",
    "where $V \\sim \\mathcal{N}(0, 1)$ and\n",
    "$$\n",
    "a = \\frac{N_L - N_{OD}}{2 N_{OD} p (1 - p)} \\approx 40\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(Z \\geqslant N_L) \\approx 10^{-350}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
