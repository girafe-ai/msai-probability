{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69835e6e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Moment-generating function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a915803",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Moment-generating function: definition\n",
    "\n",
    "**Moment-generating function** of r.v. $X$ is\n",
    "$$\n",
    "M_X(t) = \\mathbb{E}\\left[e^{tX}\\right]\n",
    "$$\n",
    "\n",
    "It does not always exist. If it exists and is finite:\n",
    "- It uniquely defines distribution of $X$\n",
    "- $M_X(t) > 0, \\forall t$ and $M_X(0) = 1$\n",
    "- $M_{aX+b}(t) = e^{bt} M_X(at)$\n",
    "- For all $k$ exists a finite moment of $X$ and is defined as $\\mathbb{E}[X^k] = M^{(k)}_X(0)$ meaning $k$-th derivative\n",
    "\n",
    "The purpose of MGF is to replace computation of expectation with differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d769cc68",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 1: Bernoulli MGF\n",
    "\n",
    "Consider $X \\sim Be(p)$. What is $M_X(t)$? Find expectation and variance using MGF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4533f0b3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 1\n",
    "\n",
    "MGF:\n",
    "$$\n",
    "M_X(t) = \\mathbb{E}\\left[e^{tX}\\right] = e^{t \\cdot 0} \\cdot \\mathbb{P}(X = 0) + e^{t \\cdot 1} \\cdot \\mathbb{P}(X = 1) = q + pe^t\n",
    "$$\n",
    "\n",
    "First and second derivatives are $pe^t$, so\n",
    "$$\n",
    "\\mathbb{E}X = M'_X(0) = pe^0 = p = M''_X(0) = \\mathbb{E}\\left[X^2\\right]\n",
    "$$\n",
    "$$\n",
    "\\mathbb{V}\\text{ar}(X) = M''_X(0) - \\left(M'_X(0)\\right)^2 = p - p^2 = p(1-p)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be679cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 2: Poisson MGF\n",
    "\n",
    "Consider $X \\sim Pois(\\lambda)$. What is $M_X(t)$? Find expectation and variance using MGF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f9da4b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 2\n",
    "\n",
    "MGF:\n",
    "$$\n",
    "M_X(t) = \\mathbb{E}\\left[e^{tX}\\right] = \\sum\\limits_{k=-\\infty}^\\infty e^{tk} \\frac{\\lambda^k}{k!} e^{-\\lambda} = e^{-\\lambda} \\sum\\limits_{k=-\\infty}^\\infty \\frac{1}{k!} \\left( \\lambda e^{t}\\right)^k = \\exp \\left( \\lambda \\left( e^t - 1 \\right) \\right)\n",
    "$$\n",
    "\n",
    "First derivative:\n",
    "$$\n",
    "M'_X(t) = \\lambda e^t \\exp \\left( \\lambda \\left( e^t - 1 \\right) \\right)\n",
    "$$\n",
    "\n",
    "Expectation $M'_X(0) = \\lambda$. Second derivative:\n",
    "$$\n",
    "M''_X(0) = \\lambda e^t \\exp \\left( \\lambda \\left( e^t - 1 \\right) \\right) + \\lambda e^t \\exp \\lambda e^t \\left( \\lambda \\left( e^t - 1 \\right) \\right)\n",
    "$$\n",
    "\n",
    "Second moment $M''_X(0) = \\lambda + \\lambda^2$. Variance $\\mathbb{V}\\text{ar}(X) = \\lambda + \\lambda^2 - \\lambda^2 = \\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc530156",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 3: Gaussian MGF\n",
    "\n",
    "Consider $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$. What is $M_X(t)$? Find expectation and variance using MGF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ce7a2c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 3\n",
    "\n",
    "First let's find for $Y \\sim \\mathcal{N}(0, 1)$, then apply properties.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "M_Y(t) & = \\mathbb{E}\\left[e^{tY}\\right] = \\frac{1}{\\sqrt{2\\pi}} \\int\\limits_{-\\infty}^\\infty e^{tx} e^{-x^2 / 2} dx = \\frac{1}{\\sqrt{2\\pi}} \\int\\limits_{-\\infty}^\\infty \\exp\\left( -\\frac{x^2 - 2tx}{2}\\right) dx = \\\\\n",
    "& = \\frac{1}{\\sqrt{2\\pi}} \\int\\limits_{-\\infty}^\\infty \\exp\\left( -\\frac{(x - t)^2 - t^2}{2}\\right) dx = \\\\\n",
    "& = \\exp\\left( \\frac{t^2}{2} \\right) \\frac{1}{\\sqrt{2\\pi}} \\int\\limits_{-\\infty}^\\infty \\exp\\left( -\\frac{(x - t)^2}{2}\\right) dx = \\exp\\left( \\frac{t^2}{2} \\right)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09571b25",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 3 (continued)\n",
    "\n",
    "From properties, $M_X(t) = e^{\\mu t} M_Y(\\sigma t) = \\exp \\left( \\mu t + \\frac{t^2 \\sigma^2}{2} \\right)$. First derivative:\n",
    "$$\n",
    "M'_X(t) = \\left( \\mu + t \\sigma^2 \\right) \\exp \\left( \\mu t + \\frac{t^2 \\sigma^2}{2} \\right)\n",
    "$$\n",
    "\n",
    "Second derivative:\n",
    "$$\n",
    "M''_X(t) = \\sigma^2 \\exp \\left( \\mu t + \\frac{t^2 \\sigma^2}{2} \\right) + \\left( \\mu + t \\sigma^2 \\right)^2  \\exp \\left( \\mu t + \\frac{t^2 \\sigma^2}{2} \\right)\n",
    "$$\n",
    "\n",
    "Expectation: $M'_X(0) = \\mu$, variance $M''_X(0) - \\left( M'_X(0) \\right)^2 = \\sigma^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf80980",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Random vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5464a7fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random vector: definition\n",
    "Consider probability space $(\\Omega, \\mathcal{F}, \\mathbb{P})$. Then, a **random vector** is a borel function\n",
    "$$\n",
    "\\mathbf{X}: \\Omega \\to \\mathbb{R}^n,\n",
    "$$\n",
    "where $\\mathbf{X} = (X_1, \\ldots, X_n)^\\top$. Every component $X_i$ of the vector is a random variable. The converse is also true: for any r.v.s $X_1, \\ldots, X_n$ a vector $(X_1, \\ldots, X_n)^\\top$ is a random vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8febda80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random vector: distribution\n",
    "\n",
    "The distribution of a random vector $\\mathbf{X} = (X_1, \\ldots, X_n)^\\top$ can be described via **multivariate  (joint) cumulative distribution function**:\n",
    "$$\n",
    "F_{\\mathbf{X}}(\\mathbf{x}) = \\mathbb{P}(X_1 < x_1, X_2 < x_2, \\ldots, X_n < x_n)\n",
    "$$\n",
    "\n",
    "Properties of multivariate CDF:\n",
    "- $\\lim_{x_i \\to -\\infty} F_{\\mathbf{X}}(\\mathbf{x}) = 0$ but $\\lim_{x_1, \\ldots, x_n \\to \\infty} F_{\\mathbf{X}}(\\mathbf{x}) = 1$\n",
    "- $\\lim_{x_i \\to \\infty} F_{\\mathbf{X}}(\\mathbf{x}) = $ the function $F$ of everything except $x_i$\n",
    "- $F_{\\mathbf{X}}(\\mathbf{x})$ is non-decreasing and left-continuous in every component\n",
    "- Supermodulatiry: $F_{\\mathbf{X}}(x_1, \\ldots, x_i, \\ldots, x_n) - F_{\\mathbf{X}}(x_1, \\ldots, x_i - \\varepsilon, \\ldots, x_n) \\geqslant 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfe0fe2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random vector: distribution\n",
    "\n",
    "If $X$ has continuous distribution, then exists **multivariate (joint) probability density function**, i.e. non-negative function $f_{\\mathbf{X}}(\\cdot)$ such that\n",
    "$$\n",
    "    \\mathbb{P}(\\mathbf{X} \\in B) = \\int_B f_{\\mathbf{X}}(x_1, \\ldots, x_n) dx_1 \\ldots dx_n\n",
    "$$\n",
    "\n",
    "PDF can also be found from CDF:\n",
    "$$\n",
    "    f_{\\mathbf{X}}(\\mathbf{x}) = \\frac{\\partial^n F_{\\mathbf{X}}(\\mathbf{x})}{\\partial x_1 \\ldots \\partial x_n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb2e786",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random vector: independence\n",
    "\n",
    "If all r.v.s $X_i$ are independent, then\n",
    "$$\n",
    "\\begin{cases}\n",
    "F_{\\mathbf{X}}(\\mathbf{x}) & = \\prod\\limits_{i=1}^n F_{X_i}(x_i), \\\\\n",
    "f_{\\mathbf{X}}(\\mathbf{x}) & = \\prod\\limits_{i=1}^n f_{X_i}(x_i)\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f0c419",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random vector: moments\n",
    "\n",
    "**Mathematical expectation** of a random vector is a vector of mathematical expectations of its components:\n",
    "$$\n",
    "\\mathbb{E}\\left[\\mathbf{X}\\right] = (\\mathbb{E}X_1, \\ldots, \\mathbb{E}X_n)^\\top\n",
    "$$\n",
    "\n",
    "Second moments of a random vector are described with **covariance matrix** $\\mathbb{V}\\text{ar}(\\mathbf{X}) = \\Sigma$, where\n",
    "$$\n",
    "\\Sigma_{ij} = \\operatorname{cov}(X_i, X_j)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4059d8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\Sigma_{ij} = \\operatorname{cov}(X_i, X_j) = \\mathbb{E} \\left[ (X_i - \\mathbb{E} X_i) (X_j - \\mathbb{E} X_j) \\right]\n",
    "$$\n",
    "\n",
    "In particular, the diagonal elements are variances: $\\Sigma_{ii} = \\mathbb{V}\\text{ar}(X_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c74f30b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random vector: covariance matrix\n",
    "\n",
    "Matrix notation for covariance matrix is $\\mathbb{V}\\text{ar}(\\mathbf{X}) = \\mathbb{E}\\left[(\\mathbf{X} - \\mathbb{E}[\\mathbf{X}]) (\\mathbf{X} - \\mathbb{E}[\\mathbf{X}])^\\top\\right]$.\n",
    "\n",
    "Properties of convariance matrix:\n",
    "- Symmetry $\\Sigma^\\top = \\Sigma$\n",
    "- Non-negative semi-definite: $a^\\top \\Sigma a \\geqslant 0, \\forall a$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cd49a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random vector: marginal and conditional distributions\n",
    "\n",
    "**Marginal distribution** is the distribution of a subset of a random vector. For example, consider r.v. $\\mathbf{X} \\in \\mathbb{R}^n$ and let's view it as two vectors, $\\mathbf{Y} \\in \\mathbb{R}^k$ and $\\mathbf{Z} \\in \\mathbb{R}^{n-k}$, stacked: $\\mathbf{X} = (\\mathbf{Y}^\\top, \\mathbf{Z}^\\top)^\\top$. The marginal distribution of $\\mathbf{Z}$ then will be:\n",
    "$$\n",
    "f_{\\mathbf{Z}}(\\mathbf{z}) = \\int_{\\mathbb{R}^k} f_{\\mathbf{X}}(\\mathbf{y}, \\mathbf{z}) d \\mathbf{y}\n",
    "$$\n",
    "\n",
    "In words, we take distribution of $\\mathbf{X}$ and **integrate out** everything not realted to $\\mathbf{Z}$.\n",
    "\n",
    "We may also define **conditional distribution**:\n",
    "$$\n",
    "f_{\\mathbf{Y}|\\mathbf{Z}=\\mathbf{z}}(\\mathbf{y}) = \\frac{f_{\\mathbf{X}}(\\mathbf{y}, \\mathbf{z})}{f_{\\mathbf{Z}}(\\mathbf{z})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6d7afe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 4: joint, marginal and conditional distributions for discrete case\n",
    "\n",
    "Let $X$ be the indicator of the sampled individual being a current smoker, and let $Y$ be the indicator of his developing lung cancer at some point in his life. Suppose the joint PMF is as follows:\n",
    "\n",
    "||$Y=1$|$Y=0$|\n",
    "|--|--|--|\n",
    "|$X=1$|$\\frac{5}{100}$|$\\frac{20}{100}$|\n",
    "|$X=0$|$\\frac{3}{100}$|$\\frac{72}{100}$|\n",
    "\n",
    "Find the marginal and consitional distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf1ccef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 4\n",
    "\n",
    "||$Y=1$|$Y=0$|\n",
    "|--|--|--|\n",
    "|$X=1$|$\\frac{5}{100}$|$\\frac{20}{100}$|\n",
    "|$X=0$|$\\frac{3}{100}$|$\\frac{72}{100}$|\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(X = x) = \\sum_y \\mathbb{P}(X = x, Y = y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb91023",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "||$Y=1$|$Y=0$|$\\text{Sum}$|\n",
    "|--|--|--|--|\n",
    "|$X=1$|$\\frac{5}{100}$|$\\frac{20}{100}$|$\\frac{25}{100}$|\n",
    "|$X=0$|$\\frac{3}{100}$|$\\frac{72}{100}$|$\\frac{75}{100}$|\n",
    "|$\\text{Sum}$|$\\frac{8}{100}$|$\\frac{92}{100}$|$\\frac{100}{100}$|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf7694e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 4\n",
    "\n",
    "||$Y=1$|$Y=0$|\n",
    "|--|--|--|\n",
    "|$X=1$|$\\frac{5}{100}$|$\\frac{20}{100}$|\n",
    "|$X=0$|$\\frac{3}{100}$|$\\frac{72}{100}$|\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(Y = y | X = x) = \\frac{\\mathbb{P}(X = x, Y = y)}{\\mathbb{P}(X = x)}\n",
    "$$\n",
    "\n",
    "Example: if the person is a smoker ($X = 1$), then $\\mathbb{P}(Y = 1 | X = 1) = \\frac{\\mathbb{P}(X = 1, Y = 1)}{\\mathbb{P}(X = 1)} = \\frac{5/100}{25/100} = 0.2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e044a510",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 5 (unit disc)\n",
    "\n",
    "Consider a random point on unit disc with random coordinates $(X, Y)$. What is the joint, marginal and conditional PDF for the coordinates?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f87daba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 5\n",
    "\n",
    "The joint is\n",
    "$$\n",
    "f_{X, Y}(x, y) = \\begin{cases}\n",
    "\\frac1\\pi, \\text{ if } x^2 + y^2 \\leqslant 1, \\\\\n",
    "0, \\text{ else}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The marginal for $X$ is:\n",
    "$$\n",
    "f_X(x) = \\int\\limits_{-\\infty}^\\infty f_{X, Y}(x, y) dy = \\int\\limits_{-\\sqrt{1 - x^2}}^{\\sqrt{1-x^2}} \\frac{1}{\\pi} dy = \\frac{2}{\\pi} \\sqrt{1 - x^2}\n",
    "$$\n",
    "\n",
    "The conditional for $Y$ is:\n",
    "$$\n",
    "f_{Y|X=x}(x) = \\frac{f_{X, Y}(x, y)}{f_{X}(x)} = \\frac{\\frac{1}{\\pi}}{\\frac{2}{\\pi}\\sqrt{1 - x^2}} = \\frac{1}{2\\sqrt{1 - x^2}}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Слайд-шоу",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
