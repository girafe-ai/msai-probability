{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19d9a552",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Homework problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b13142",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 1\n",
    "\n",
    "Find the MGF function of $X \\sim \\Gamma(n, \\lambda)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b637bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Soltuion 1\n",
    "\n",
    "MGF of $X$:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "M_X(t) & = \\mathbb{E}\\left[e^{tX}\\right] = \\int\\limits_{-\\infty}^\\infty e^{tx} \\frac{1}{\\Gamma(n)} \\lambda^n x^{n-1} e^{-\\lambda x} dx = \\\\\n",
    "& = \\frac{1}{\\Gamma(n)} \\frac{\\lambda^n}{(\\lambda - t)^n} \\int\\limits_{-\\infty}^\\infty \\left((\\lambda - t)x\\right)^{n-1} e^{-(\\lambda-t)x} d \\left( (\\lambda - t) x \\right) = \\\\\n",
    "& = \\frac{1}{\\Gamma(n)} \\frac{\\lambda^n}{(\\lambda - t)^n} \\int\\limits_{-\\infty}^\\infty u^{n-1} e^{-u} d \\left( u \\right) = \\\\\n",
    "& = \\frac{\\lambda^n}{(\\lambda - t)^n}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f5b16",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 2\n",
    "\n",
    "While running errands, you need to go to the bank, then to the post office. Let $X \\sim Gamma(a, \\lambda)$ be your waiting time in line at the bank, and let $Y \\sim Gamma(b, \\lambda)$ be your waiting time in line at the post office (with the same $\\lambda$ for both). Assume $X$ and $Y$ are independent. What is the joint distribution of $T = X + Y$ (your total wait at the bank and post office) and $W = X/(X+Y)$ (the fraction of your waiting time spent at the bank)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233ade75",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 2\n",
    "\n",
    "Consider transform $(X, Y) \\to (T, W)$, where $T = X + Y$ and $W = \\frac{X}{X+Y}$. The inverse transform is $X = TW, Y = T(1 - W)$. The Jacobian of the **direct** transform is:\n",
    "$$\n",
    "\\left| \\det \\frac{\\partial (x, y)}{\\partial (t, w)} \\right| = \\left| \\det \\begin{pmatrix}w&t\\\\1-w&-t\\end{pmatrix} \\right| = t\n",
    "$$\n",
    "\n",
    "Then,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "f_{T,W}(t, w) & = f_{X,Y}(tw, t(1-w)) \\left| \\det \\frac{\\partial (x, y)}{\\partial (t, w)} \\right| = \\\\\n",
    "& = f_X(tw)f_Y\\left(t(1-w)\\right) t = \\\\\n",
    "& = t \\frac{1}{\\Gamma(a)} \\lambda^a (tw)^{a-1} e^{-a tw} \\frac{1}{\\Gamma(b)} \\lambda^b (t(1-w))^{b-1} e^{-b t(1-w)} = \\\\\n",
    "& = \\frac{1}{\\Gamma(a)\\Gamma(b)} w^{a-1} (1-w)^{b-1} (\\lambda t)^{a+b} e^{-\\lambda t} \\frac1t = \\\\\n",
    "& = \\left( \\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)} w^{a-1} (1-w)^{b-1} \\right) \\left( \\frac{1}{\\Gamma(a+b)} \\lambda^{a+b} t^{a+b-1} e^{-\\lambda t} \\right)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8906e87d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "f_{T,W}(t, w) = \\left( \\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)} w^{a-1} (1-w)^{b-1} \\right) \\left( \\frac{1}{\\Gamma(a+b)} \\lambda^{a+b} t^{a+b-1} e^{-\\lambda t} \\right)\n",
    "$$\n",
    "\n",
    "First, it tells us that $f_{T,W}(t,w) = f_T(t)f_W(w)$, so they are independent (total time is independent of the fraction at the bank). Second, we have expression for $f_T(t)$:\n",
    "$$\n",
    "f_T(t) = \\frac{1}{\\Gamma(a+b)} \\lambda^{a+b} t^{a+b-1} e^{-\\lambda t}\n",
    "$$\n",
    "\n",
    "In which we recognize $T \\sim Gamma(a+b, \\lambda)$. We also have expression for $f_W(w)$:\n",
    "$$\n",
    "f_W(w) = \\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)} w^{a-1} (1-w)^{b-1}\n",
    "$$\n",
    "\n",
    "In which we recognize $W \\sim Beta(a, b)$. This gives us expression for beta function:\n",
    "$$\n",
    "\\beta(a, b) = \\frac{\\Gamma(a)\\Gamma(b)}{\\Gamma(a + b)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c639e62e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 3\n",
    "\n",
    "Use the result of previous problem to find the expectation and variance of Beta distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54229c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 3\n",
    "\n",
    "Result of previous problem: for $X \\sim Gamma(a, \\lambda)$ and $Y \\sim Gamma(b, \\lambda)$, we have $T = X + Y \\sim Gamma(a+b, \\lambda)$ and $W = \\frac{X}{X+Y} \\sim Beta(a, b)$ independent.\n",
    "\n",
    "Now,\n",
    "$$\n",
    "\\mathbb{E}\\left[TW\\right] = \\mathbb{E}\\left[T\\right]\\mathbb{E}\\left[W\\right]\n",
    "$$\n",
    "$$\n",
    "\\mathbb{E}\\left[(X+Y) \\frac{X}{X+Y}\\right] = \\mathbb{E}\\left[X+Y\\right]\\mathbb{E}\\left[W\\right]\n",
    "$$\n",
    "$$\n",
    "\\mathbb{E}\\left[W\\right] = \\frac{\\mathbb{E}\\left[X\\right]}{\\mathbb{E}\\left[X+Y\\right]} = \\frac{a/\\lambda}{a/\\lambda + b/\\lambda} = \\frac{a}{a+b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b1ce1d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conditional expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f979236d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional expectation: definition\n",
    "\n",
    "We know conditional probability. Consider r.v.s $X$ (discrete) and $Z$ (discrete with alphabet $E$), then for event $X = x$\n",
    "$$\n",
    "\\mathbb{P}(X = x | Z = z) = \\frac{\\mathbb{P}(X = x, Z = z)}{\\mathbb{P}(Z = z)}\n",
    "$$\n",
    "\n",
    "A function $x \\to \\mathbb{P}(X = x | Z = z)$ is the conditional law of $X$ given $Z = z$. \n",
    "\n",
    "But what if we had not one event $Z = z$, but many events $A_i = \\{Z = z_i\\}$? We can still do it, by plugging a set of events $\\mathcal{A} = \\{A_1, \\ldots, A_n\\}$ into function $h(\\cdot)$.\n",
    "\n",
    "What if want to account for all events with their probabilities? We can still use our function $h(\\cdot)$ by plugging the random variable $Z$ into it! $h(Z) = \\mathbb{E}[X|Z]$ then will be a random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558fcd04",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Properties\n",
    "- $\\mathbb{E}[\\alpha X_1 + \\beta X_2|Z] = \\alpha\\mathbb{E}[X_1|Z] + \\beta \\mathbb{E}[X_2|Z]$\n",
    "- If $X \\geqslant 0$ a.s., then $\\mathbb{E}[X|Z] \\geqslant 0$\n",
    "- $\\mathbb{E}\\left[\\mathbb{E}[X|Z]\\right] = \\mathbb{E}[X]$\n",
    "- For any function $h(\\cdot)$ we have $\\mathbb{E}[Xh(Z)|Z] = h(Z) \\mathbb{E}[X|Z]$ a.s.\n",
    "- If $X$ and $Z$ are independent, then $\\mathbb{E}[X|Z] = \\mathbb{E}[X]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aba7e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 1\n",
    "\n",
    "A stick of length 1 is broken at point $X$ chosen uniformly at random. Given that $X = x$, we choose another\n",
    "breakpoint $Y$ uniformly at the interval $[0,x]$. Find $\\mathbb{E}[Y|X]$ and its mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc23fd3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 1\n",
    "\n",
    "We have $X \\sim U[0, 1]$ and $Y|X=x \\sim U[0, x]$.\n",
    "\n",
    "The expected value of $U[0, x]$ distribution is $\\mathbb{E}[Y|X=x] = \\tfrac{x}{2}$.\n",
    "\n",
    "To get $\\mathbb{E}[Y|X]$ we take this expected value and plug in our random variable, so\n",
    "$$\n",
    "\\mathbb{E}[Y|X] = \\frac{X}{2}\n",
    "$$\n",
    "\n",
    "To find the expectation $\\mathbb{E}\\left[\\mathbb{E}[Y|X]\\right]$, we use the property:\n",
    "$$\n",
    "\\mathbb{E}\\left[\\mathbb{E}[Y|X]\\right] = \\mathbb{E}[Y] = \\mathbb{E}\\left[\\frac{X}{2}\\right] = \\frac12 \\mathbb{E}[X] = \\frac14\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a46d7d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 2\n",
    "\n",
    "Let $Z \\sim \\mathcal{N}(0, 1)$ and $Y = Z^2$. Find $\\mathbb{E}[Y|Z]$ and $\\mathbb{E}[Z|Y]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6c7fc5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 2\n",
    "\n",
    "We have $Y = h(Z) = Z^2$. Therefore\n",
    "$$\n",
    "\\mathbb{E}[Y|Z] = \\mathbb{E}[h(Z)|Z] = h(Z) = Z^2\n",
    "$$\n",
    "\n",
    "To get the converse $\\mathbb{E}[Z|Y]$, let's first start with\n",
    "$$\n",
    "\\mathbb{E}[Z|Y = y] = \\sqrt{y} \\mathbb{P}(Z = \\sqrt{y} | Y = y) + (- \\sqrt{y}) \\mathbb{P}(Z = - \\sqrt{y} | Y = y) = \\sqrt{y} p - \\sqrt{y} p = 0\n",
    "$$\n",
    "\n",
    "By plugging in r.v. $Y$ we still get 0, so $\\mathbb{E}[Z|Y] = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ebc0e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 3\n",
    "\n",
    "Let $X_1, \\ldots, X_n$ be i.i.d. r.v.s and $S_n = X_1 + \\ldots + X_n$. Find $\\mathbb{E}[X_1|S_n]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58c9bfa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 3\n",
    "\n",
    "By symmetry,\n",
    "$$\n",
    "\\mathbb{E}[X_1|S_n] = \\mathbb{E}[X_2|S_n] = \\ldots = \\mathbb{E}[X_n|S_n]\n",
    "$$\n",
    "\n",
    "By linearity,\n",
    "$$\n",
    "\\mathbb{E}[X_1|S_n] + \\mathbb{E}[X_2|S_n] + \\ldots + \\mathbb{E}[X_n|S_n] = \\mathbb{E}[S_n|S_n] = S_n\n",
    "$$\n",
    "\n",
    "So,\n",
    "$$\n",
    "\\mathbb{E}[X_1|S_n] = \\frac{1}{n} S_n = \\overline{X}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7368f5f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example 4\n",
    "\n",
    "Regression uses the following to make a prediction: $\\hat{Y} = \\mathbb{E}[Y|X]$. Linear regression assumes $\\mathbb{E}[Y|X] = a + bX$.\n",
    "\n",
    "1. Show that an equivalent way to express this is to write $Y = a + bX + \\varepsilon$ with $\\mathbb{E}[\\varepsilon|X] = 0$.\n",
    "2. Solve for the constants $a$ and $b$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab5b998",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 4.1\n",
    "\n",
    "1. Let $Y = a + bX + \\varepsilon$, then\n",
    "$$\n",
    "\\mathbb{E}[Y|X] = \\mathbb{E}[a + bX + \\varepsilon|X] = a + bX + \\mathbb{E}[\\varepsilon|X] = a + bX\n",
    "$$\n",
    "2. Let $\\mathbb{E}[Y|X] = a + bX$ and define $\\varepsilon = Y - (a + bX)$, then $Y = a + bX + \\varepsilon$ and\n",
    "$$\n",
    "\\mathbb{E}[\\varepsilon|X] = \\mathbb{E}[Y - (a + bX)|X] = \\mathbb{E}[Y|X] - \\mathbb{E}[a + bX|X] = a + bX - (a + bX) = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de32786",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 4.2\n",
    "\n",
    "1. Expectation of $Y$\n",
    "    $$\n",
    "    \\mathbb{E}[Y] = \\mathbb{E}\\left[\\mathbb{E}[Y|X]\\right] = \\mathbb{E}[a + bX] = a + b\\mathbb{E}[X]\n",
    "    $$\n",
    "\n",
    "2. $\\varepsilon$ has zero mean\n",
    "    $$\n",
    "    \\mathbb{E}[\\varepsilon] = \\mathbb{E}\\left[\\mathbb{E}[\\varepsilon|X]\\right] = \\mathbb{E}[0] = 0\n",
    "    $$\n",
    "\n",
    "3. $X$ and $\\varepsilon$ uncorrelated\n",
    "    $$\n",
    "    \\mathbb{E}[\\varepsilon X] = \\mathbb{E}\\left[\\mathbb{E}[\\varepsilon X|X]\\right] = \\mathbb{E} X \\left[\\mathbb{E}[\\varepsilon|X]\\right] = \\mathbb{E}[X \\cdot 0] = 0\n",
    "    $$\n",
    "\n",
    "Now, take $Y = a + bX + \\varepsilon$ and take covariance with $X$ at both sides: \n",
    "$$\n",
    "\\operatorname{cov}(X,Y) = \\operatorname{cov}(X,a) + \\operatorname{cov}(X,bX) + \\operatorname{cov}(X,\\varepsilon) = b \\mathbb{V}\\text{ar}(X)\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "$$\n",
    "b = \\frac{\\operatorname{cov}(X,Y)}{\\mathbb{V}\\text{ar}(X)}\n",
    "$$\n",
    "$$\n",
    "a = \\mathbb{E}[Y] - \\frac{\\operatorname{cov}(X,Y)}{\\mathbb{V}\\text{ar}(X)} \\mathbb{E}[X]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f112d4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 5\n",
    "\n",
    "One of two identical-looking coins is picked from a hat randomly, where one coin has probability $p_1$ of success and the other has probability $p_2$ of success. Let $X$ be the number of successes after flipping the chosen coin $n$ times. Find the mean of $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c321c1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 5\n",
    "\n",
    "Denote $Y \\sim Be(1/2)$ the r.v. that we chose coin 1, $X_1 \\sim Bi(n, p_1)$ and $X_2 \\sim Bi(n, p_2)$ the number of successes for trials with different coins. Then\n",
    "$$\n",
    "X = Y X_1 + (1 - Y) X_2\n",
    "$$\n",
    "\n",
    "Use the tower rule:\n",
    "$$\n",
    "\\mathbb{E}[X] = \\mathbb{E}\\left[\\mathbb{E}[X|Y]\\right]\n",
    "$$\n",
    "\n",
    "Now we need to find\n",
    "$$\n",
    "\\mathbb{E}[X|Y = y] = y np_1 + (1 - y) np_2\n",
    "$$\n",
    "\n",
    "Then,\n",
    "$$\n",
    "\\mathbb{E}[X|Y] = Y np_1 + (1 - Y) np_2\n",
    "$$\n",
    "\n",
    "Finally,\n",
    "$$\n",
    "\\mathbb{E}[X] = \\mathbb{E}\\left[Y np_1 + (1 - Y) np_2\\right] = \\frac{n}{2} (p_1 + p_2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812beebf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problem 6\n",
    "\n",
    "Let $N \\sim Pois(\\lambda_1)$ be the number of movies released in 2022. Suppose that for every movie independently the number of tickets sold in Dolgoprudnyy is $X_i \\sim Pois(\\lambda_2)$. Find the mean of the total number of movie tickets sold in Dolgoprudnyy in 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd2258",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Solution 6\n",
    "\n",
    "Denote $S_N = X_1 + \\ldots + X_N$. We need to find $\\mathbb{E}[S_N]$. Use tower rule:\n",
    "$$\n",
    "\\mathbb{E}[S_N] = \\mathbb{E}\\left[\\mathbb{E}[S_N|N]\\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[S_N|N = n] = \\mathbb{E}[X_1 + \\ldots + X_N|N = n] = \\mathbb{E}[X_1 + \\ldots + X_n] = n \\mathbb{E}[X_1] = n \\lambda_2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[S_N|N] = N \\lambda_2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbb{E}[S_N] = \\mathbb{E}\\left[N \\lambda_2\\right] = \\lambda_1 \\lambda_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfabb16",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Homework problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498aed6c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Homework problems\n",
    "\n",
    "1. Emails arrive one at a time in an inbox. Let $T_n$ be the time at which the $n$-th email arrives (measured on a continuous scale from some starting point in time). Suppose that the waiting times between emails are i.i.d. $Exp(\\lambda)$, i.e., $T_1, T_2 - T_1, T_3 − T_2, \\ldots \\sim Exp(\\lambda)$. Each email is non-spam with probability $p$, and spam with probability $q = 1 − p$ (independently of the other emails and of the waiting times). Let $X$ be the time at which the first non-spam email arrives (so $X$ is a continuous r.v.\n",
    "    - Find the mean of $X$.\n",
    "    - Find the MGF of $X$. What famous distribution does this imply that X has?\n",
    "    \n",
    "    Hint for both parts: Let $N$ be the number of emails until the first non-spam (including that one), and write $X$ as a sum of $N$ terms, then condition on $N$.\n",
    "    \n",
    "2. Customers arrive at a store according to a Poisson process of rate $\\lambda$ customers per hour. Each makes a purchase with probability $p$, independently. Given that a customer makes a purchase, the amount spent has mean $\\mu$ (in dollars) and variance $\\sigma^2$.\n",
    "\n",
    "    - Find the mean of how much a random customer spends (note that the customer may not make a purchase).\n",
    "    - Find the mean of the revenue the store obtains in an 8-hour time interval, using previous subproblem."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
